\documentclass{article}

\usepackage[italian]{babel}
\usepackage[margin=2cm]{geometry}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{mathabx}
\usepackage{cancel}
\usepackage{cmll}
\usepackage{halloweenmath}
\usepackage{dsfont}
\usepackage{soulutf8}
\usepackage{contour}
\usepackage[scr]{rsfso}
\usepackage{bm}
\usepackage{float}
\usepackage{hyperref}

\theoremstyle{plain}
\newtheorem{teorema}{Teorema}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposizione}{Proposizione}[section]
\newtheorem*{corollario}{Corollario}
\newtheorem*{principio}{Principio}

\theoremstyle{definition}
\newtheorem{definizione}{Definizione}[section]
\newtheorem*{notazione}{Notazione}
\newtheorem{osservazione}{Osservazione}[section]
\newtheorem{esercizio}{Esercizio}[section]
\newtheorem{esempio}{Esempio}[section]

\theoremstyle{remark}
\newtheorem*{nota}{Nota}
\newtheorem*{NB}{NB}

\newenvironment{soluzione}
	{\renewcommand\qedsymbol{$\mathwitch*$}\begin{proof}[Soluzione]}
	{\end{proof}}

\renewcommand{\qedsymbol}{$\mathrightghost$}

\setuldepth{Flat}
\contourlength{0.8pt}

\newcommand{\uline}[1]{%
  \ul{{\phantom{#1}}}%
  \llap{\contour{white}{#1}}%
}

\title{Appunti di Probabilità e Statistica}
\author{Riccardo Agatea}
\date{}

\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=black,  %choose some color if you want links to stand out
}

\begin{document}
\pagenumbering{gobble}
\maketitle
\begin{center}
	Repo: \url{https://github.com/RiccardoAgatea/Probabilita-e-Statistica-2019}\\
	Questi sono gli appunti che ho preso a lezione. Non sono stati controllati da alcun professore, se trovate errori fatemelo notare e correggo.
\end{center}
\newpage
\pagenumbering{roman}
\tableofcontents
\newpage
\pagenumbering{arabic}
\section{Introduzione} % (fold)
\label{sec:introduzione}
La probabilità si prefigge di studiare eventi casuali in modo matematico. Per evento casuale non si intende solo un evento prettamente aleatorio, come il lancio di un dado, ma anche un evento essenzialmente deterministico che richiederebbe, per essere previsto, lo studio di un sistema complesso, influenzato da un numero così alto di variabili, che risulta più semplice ed efficiente studiarlo come se fosse casuale. Inoltre, in alcune situazioni la probabilità può intervenire nonostante il caso sia completamente assente: uno degli esempi più importanti è l'integrazione con il metodo Monte Carlo. Considerato un integrale
\begin{equation*}
	I=\int_0^1 f(x)dx
\end{equation*}
difficilmente risolvibile individuando un'antiderivata di $f(x)$, dal teorema della media integrale è noto che
\begin{equation*}
	\exists\xi\in [0,1]\colon\int_0^1 f(x)dx=f(\xi)
\end{equation*}
Per ricavare una stima di $I$ è possibile considerare un insieme $X=\{x_1,x_2,...,x_n\}s$ di valori casuali tale che $X\subseteq [0,1]$. La media dei valori assunti dalla funzione in questi punti, per le leggi dei grandi numeri, tende a $I$ per $n\to+\infty$:
\begin{equation*}
	\frac{1}{n}*\sum_{i=1}^{n}f(x_i)\xrightarrow[n\to+\infty]{}I
\end{equation*}
% section introduzione (end)
\section{Spazio di Probabilità} % (fold)
\label{sec:spazio_di_probabilità}
\subsection{Definizioni} % (fold)
\label{sub:definizioni}
\begin{definizione}
	Sia $\Omega$ un insieme non vuoto, sia $\mathscr{F}$ una famiglia di sottoinsiemi di $\Omega$ (cioè un insieme di sottoinsiemi di $\Omega$), e sia
	\begin{equation*}
		P:\mathscr{F}\to[0,1]
	\end{equation*}
	una funzione tale che $P(\Omega)=1$. Si chiama spazio di probabilità la terna ordinata
	\begin{equation*}
		(\Omega,\mathscr{F},P)
	\end{equation*}
\end{definizione}
\begin{itemize}
	\item $\Omega$ si chiama spazio degli eventi elementari, contiene tutti i risultati possibili di un dato esperimento. I suoi elementi si dicono eventi elementari o esiti specifici.
	\item $\mathscr{F}$ ha la struttura di una \sigma-algebra (concetto che verrà studiato più avanti); intuitivamente contiene tutti gli eventi che si vogliono studiare in senso probabilistico.
	\item P si dice misura di probabilità. Se $E\in\mathscr{F}$, e quindi $E$ è un evento, $P(E)$ è la probabilità che $E$ si realizzi. Si intende che se $P(E)=0$ allora $E$ non si verifica mai, se $P(E)=1$ allora $E$ si verifica sempre.
\end{itemize}
\begin{NB}
	Per uno stesso esperimento $\Omega$, $\mathscr{F}$ e $P$ non sono necessariamente unici. Generalmente si cerca di scegliere $\Omega$ in modo che sia il più ridotto possibile, per cercare di minimizzare la complessità degli eventi da studiare.
\end{NB}
Sono dati alcuni esempi di esperimenti, e dei relativi spazi degli eventi elementari.
\begin{esempio}
	Esperimento: lancio di una moneta.
	\begin{equation*}
		\Omega=\{T,C\}
	\end{equation*}
\end{esempio}
\begin{esempio}
	Esperimento: 3 lanci consecutivi di una moneta.
	\begin{equation*}
		\Omega=\{TTT, TTC, TCT, TCC, CTT, CTC, CCT, CCC\}
	\end{equation*}
\end{esempio}
\begin{esempio}
	Esperimento: conteggio del numero di volte in cui esce testa su 3 lanci di una moneta.
	\begin{equation*}
		\Omega=\{0,1,2,3\}
	\end{equation*}
\end{esempio}
\begin{esempio}
	Esperimento: conteggio del numero di lanci necessari affinchè esca testa la prima volta.
	\begin{equation*}
		\Omega=\{1,2,3,...\}=\mathbb{N}
	\end{equation*}
\end{esempio}
\begin{esempio}
	Esperimento: misura della durata di vita di una lampadina (supponendo che la sensibilità del sistema di misura sia essenzialmente nulla, cioè che le misure siano corrette fino all'infinitesima cifra significativa).
	\begin{equation*}
		\Omega=\mathds{R}_+\quad\text{oppure}\quad\Omega=[0,a]\subsetneqq\mathds{R}_+
	\end{equation*}
\end{esempio}
Introduciamo alcuni concetti:
\begin{definizione}
	Uno spazio di probabilità $(\Omega,\mathscr{F},P)$ si dice discreto se $\Omega$ è finito o numerabile:
	\begin{equation*}
		\lvert\Omega\rvert\leq\lvert\mathbb{N}\rvert
	\end{equation*}
\end{definizione}
\begin{definizione}
	Uno spazio di probabilità $(\Omega,\mathscr{F},P)$ si dice continuo se $\Omega$ è non numerabile:
	\begin{equation*}
		\lvert\Omega\rvert=\lvert\mathds{R}\rvert
	\end{equation*}
\end{definizione}
\begin{definizione}
	Sia $\omega\in\Omega$ il risultato osservato dall'esecuzione di un dato esperimento, e sia $E\in\mathscr{F}$ un evento. Si dice che $E$ si è verificato se e solo se 
	\begin{equation*}
		\omega\in E
	\end{equation*}
\end{definizione}
\begin{esempio}
	Esperimento: 3 lanci consecutivi di una moneta.
	Consideriamo:
	\begin{align*}
		\Omega&=\{TTT, TTC, TCT, TCC, CTT, CTC, CCT, CCC\}\\
		E&=\{\omega\in\Omega\mid\text{testa e croce si alternano}\}
	\end{align*}
	Dall'esecuzione dell'esperimento, si osserva $\omega=TTC$.
	\begin{equation*}
		\omega\notin E \Rightarrow E\ \text{non si è verificato}
	\end{equation*}
	Ripetendo l'esperimento si osserva $\omega=TCT$.
	\begin{equation*}
		\omega\in E \Rightarrow E\ \text{si è verificato}
	\end{equation*}
\end{esempio}
Due particolari eventi sempre presenti in $\mathscr{F}$ sono $\emptyset$ e $\Omega$:
\begin{itemize}
	\item $\emptyset$ rappresenta il non presentarsi di alcuno degli eventi elementari in $\Omega$. Chiaramente almeno uno degli eventi elementari si deve presentare, quindi $\emptyset$ non si verifica mai.
	\item $\Omega$ rappresenta il presentarsi di uno degli eventi elementari, senza limitazioni, e quindi si verifica sempre.
\end{itemize}
% subsection definizioni (end)
\subsection{Operazioni sugli Insiemi} % (fold)
\label{sub:operazioni_sugli_insiemi}
Consideriamo uno spazio di probabilità $(\Omega,\mathscr{F},P)$, e due eventi $E,F\in\mathscr{F}$. Essendo $\mathscr{F}$ una famiglia di sottoinsiemi di $\Omega$, $E$ e $F$ sono insiemi, e quindi si possono applicare ad essi le comuni operazioni sugli insiemi. Quelli che si ottengono sono ancora eventi di $\mathscr{F}$, di cui si può studiare il verificarsi in funzione del verificarsi di $E$ e $F$.
\begin{itemize}
	\item $E\cap F$ si verifica $\Leftrightarrow$ sia $E$ che $F$ si verificano
	\item $E\cup F$ si verifica $\Leftrightarrow$ almeno uno fra $E$ e $F$ si verifica
	\item $E^C$ si verifica $\Leftrightarrow$ $E$ non si verifica
	\item $E\smallsetminus F$ si verifica $\Leftrightarrow$ $E$ si verifica e $F$ non si verifica
	\item $E\Delta F$ si verifica $\Leftrightarrow$ solo uno fra $E$ ed $F$ si verifica
\end{itemize}
\begin{definizione}
	$E$ ed $F$ si dicono incompatibili se sono disgiunti:
	\begin{equation*}
		E\cap F=\emptyset
	\end{equation*}
\end{definizione}
Chiaramente, per gli elementi di $\mathscr{F}$ continuano a valere la proprietà distributiva dell'intersezione sull'unione e dell'unione sull'intersezione, e le due leggi di De Morgan. Usando le leggi di De Morgan, è sempre possibile esprimere un'espressione in funzione del complemento e di una fra unione e intersezione.
\paragraph{Partizioni} % (fold)
\label{par:partizioni}
Ricordiamo la definizione di partizione di un insieme:
\begin{definizione}
	Sia $A$ un insieme, sia $(A_i)_i$ una famiglia di suoi sottoinsiemi. $(A_i)_i$ si dice partizione di $A$ se e solo se
	\begin{align*}
		&\bigcup_i A_i =A\\
		&A_i\cap A_j =\emptyset \quad\forall i\neq j
	\end{align*}
\end{definizione}
Se l'insieme considerato è uno spazio degli eventi $\Omega$, allora una sua partizione rappresenta una famiglia di eventi incompatibili, ma per i quali c'è la garanzia che uno e uno solo di essi si verifichi. Dato un evento $F\subseteq\Omega$ e una partizione $(E_i)_i$ di $\Omega$, è sempre possibile \textit{scomporre} $F$ rispetto $(E_i)_i$, cioè si può sempre rappresentare $F$ come l'unione delle intersezioni di $F$ con gli insiemi di $(E_i)_i$:
\begin{equation*}
	F=\bigcup_i (F\cap E_i)
\end{equation*}
Chiaramente, siccome $(E_i)_i$ è una partizione di $\Omega$, $(F\cap E_i)_i$ è una partizione di $F$. In modo simile, è sempre possibile scomporre l'unione di due eventi in una sua partizione: se $E,F\subseteq\Omega$ allora
\begin{equation*}
	E\cup F=(E\cap F^C)\cup(E^C\cap F)\cup (E\cap F)
\end{equation*}
Concettualmente, significa che "o si verifica solo $E$, o si verifica solo $F$, oppure si verificano entrambi". Un'altra scomposizione, più generalizzabile è:
\begin{equation*}
	E\cup F=E\cup(F\smallsetminus E)
\end{equation*}
In questo caso, il significato è "o si verifica $E$, e non ci interessiamo di $F$, oppure se $E$ non si verifica, allora si verifica $F$". Questa scomposizione si può generalizzare alla generica famiglia di eventi $\{E_n\}_n$:
\begin{equation*}
	\bigcup_{k=1}^n E_k=E_1 \cup\left(\bigcup_{k=2}^n \left(E_k\smallsetminus\bigcup_{j=1}^{k-1} E_j\right)\right)
\end{equation*}
\begin{esercizio}
	Dati tre eventi $E,F,G$, trovare l'evento corrispondente a
	\begin{itemize}
		\item si verifica solo $E$
		\item si verificano $E$ e $F$, ma non $G$
		\item si verifica esattamente uno degli eventi $E$, $F$, o $G$
		\item si verifica almeno uno dei tre
		\item si verificano esattamente due degli eventi
	\end{itemize}
\end{esercizio}
% paragraph partizioni (end)
% subsection operazioni_sugli_insiemi (end)
\subsection{Spazio degli Eventi} % (fold)
\label{sub:spazio_degli_eventi}
Abbiamo detto che $\mathscr{F}$ è una famiglia di sottoinsiemi di $\Omega$ che contiene tutti gli eventi che ci interessa analizzare. Diamo una definizione formale di evento:
\begin{definizione}
	Un sottoinsieme $E$ di $\Omega$ si dice evento se e solo se $E\in\mathscr{F}$.
\end{definizione}
Il fatto che $\mathscr{F}$ contenga gli eventi che ci interessano ha delle conseguenze, nello specifico significa che se un evento è presente devono essere presenti anche tutti gli eventi "equivalenti". Ad esempio, se l'evento "è uscita sempre testa" è presente, anche "non è uscita mai croce" deve essere presente, perché danno la stessa informazione. Per questo $\mathscr{F}$ è una \sigma-algebra:
\begin{definizione}
	Dato un insieme $A$ e una famiglia di suoi sottoinsiemi $\mathscr{A}\subseteq\mathds{P}(A)$, $\mathscr{A}$ è una \sigma-algebra se e solo se:
	\begin{enumerate}
		\item $\mathscr{A}\neq\emptyset$
		\item $\forall B\subseteq A\quad B\in\mathscr{A}\Rightarrow B^C\in\mathscr{A}$
		\item Presa comunque una famiglia numerabile $(B_n)_n$ di sottoinsiemi di $A$, vale
		\begin{equation*}
			\forall n\ B_n\in\mathscr{A}\Rightarrow\bigcup_i B_i\in\mathscr{A}
		\end{equation*}
	\end{enumerate}
\end{definizione}
Bastano queste condizioni perché, come abbiamo detto, tutte le operazioni fra insiemi possono essere ridotte a combinazioni di complemento e unione. Due esempi particolarmente importanti di \sigma-algebre su un dato spazio degli eventi elementari $\Omega$ sono:
\begin{esempio}
	\begin{equation*}
		\mathscr{F}=\{\emptyset, \Omega\}
	\end{equation*}
	Questa è una \sigma-algebra perché:
	\begin{enumerate}
		\item Chiaramente non è vuota
		\item $\emptyset^C=\Omega\in\mathscr{F}$ e $\Omega^C=\emptyset\in\mathscr{F}$
		\item $\emptyset\cup\Omega=\Omega\in\mathscr{F}$
	\end{enumerate}
\end{esempio}
\begin{esempio}
	\begin{equation*}
		\mathscr{F}=\mathds{P}(\Omega)
	\end{equation*}
	Con $\mathds{P}(\Omega)$ indichiamo l'insieme delle parti di $\Omega$. La dimostrazione è triviale.
\end{esempio}
\begin{definizione}
	Sia $E\subseteq\Omega$, la \sigma-algebra generata da $E$ è
	\begin{equation*}
		\mathscr{F}=\{\emptyset,\Omega,E,E^C\}
	\end{equation*}
\end{definizione}
Si dimostra che è una \sigma-algebra:
\begin{proof}
	\begin{enumerate}
		\item Trivialmente, $\mathscr{F}\neq\emptyset$
		\item 
		\begin{align*}
			\emptyset^C=\Omega&\in\mathscr{F}\\
			\Omega^C=\emptyset&\in\mathscr{F}\\
			E^C&\in\mathscr{F}\\
			(E^C)^C=E&\in\mathscr{F}
		\end{align*}
		\item Per dimostrare che $\mathscr{F}$ è chiusa rispetto l'unione non è necessario considerare le unioni con $\Omega$, perché $\Omega\cup x=\Omega\ \forall x$. Non è necessario considerare neanche $\emptyset$, perché esso è l'elemento neutro dell'unione, e quindi $\emptyset\cup x\in\mathscr{F}\Leftrightarrow x\in\mathscr{F}\ \forall x$. Resta da dimostrare che $E\cup E^C\in\mathscr{F}$, che è triviale in quanto $E\cup E^C=\Omega$.
	\end{enumerate}
\end{proof}
Le proprietà di una \sigma-algebra sono:
\begin{itemize}
	\item $\emptyset,\Omega\in\mathscr{F}\quad\forall\mathscr{F}$
	\begin{proof}
		\begin{align*}
			&\mathscr{F}\neq\emptyset\\
			\Rightarrow&\exists G\in\mathscr{F}\\
			\Rightarrow&G^C\in\mathscr{F}\\
			\Rightarrow&G\cup G^c \in\mathscr{F}\\
			\Rightarrow&\Omega\in\mathscr{F}\\
			\Rightarrow&\Omega^C=\emptyset\in\mathscr{F}\qedhere
		\end{align*}
	\end{proof}
	\item $\mathscr{F}$ è chiusa rispetto le unioni finite
	\begin{proof}
		Sia $\{E_1,...,E_n\}\subseteq\mathscr{F}$ una famiglia finita di sottoinsiemi di $\Omega$. Questa può essere estesa definendo $E_i=\emptyset\ \forall i>n$; segue:
		\begin{equation*}
			\bigcup_{i=1}^n B_i=\bigcup_{i\in\mathbb{N}} B_i\in\mathscr{F}\qedhere
		\end{equation*}
	\end{proof}
	\item $\mathscr{F}$ è chiusa rispetto le intersezioni
	\begin{proof}
		Sia $(E_n)_n\subseteq\mathscr{F}$ una famiglia numerabile di sottoinsiemi di $\Omega$.
		\begin{align*}
			 &\forall i\ E_i\in\mathscr{F}\\
			 &\Rightarrow\forall i\ E_i^C\in\mathscr{F}\\
			 &\Rightarrow\bigcup_i E_i^C\in\mathscr{F}\\
			 &\Rightarrow(\bigcup_i E_i^C)^C\in\mathscr{F}\\
			 &\Rightarrow\bigcap_i E_i\in\mathscr{F}\qedhere
		\end{align*}
	\end{proof}
\end{itemize}
Se $\Omega$ è discreto, allora si può sempre prendere $\mathscr{F}=\mathds{P}(\Omega)$, ed è quello che si fa di solito.
% subsection spazio_degli_eventi (end)
\subsection{Misura di probabilità} % (fold)
\label{sub:misura_di_probabilità}
Diamo una definizione di misura di probabilità:
\begin{definizione}
	Una funzione
	\begin{equation*}
		P\colon\mathscr{F}\to[0,1]
	\end{equation*}
	si dice misura di probabilità se
	\begin{enumerate}
		\item $P(\Omega)=1$
		\item $P$ è \sigma-additiva, cioè: sia $(E_i)_i\subseteq\mathscr{F}$ una famiglia numerabile di eventi mutualmente incompatibili, allora
		\begin{equation*}
			P(\bigcup_i E_i)=\sum_i P(E_i)
		\end{equation*}
	\end{enumerate}
\end{definizione}
Le proprietà di $P$ sono:
\begin{itemize}
	\item $\forall E\in\mathscr{F}\quad P(E^C)=1-P(E)$
	\begin{proof}
		\begin{align*}
			&E\cup E^C=\Omega\\
			&\Rightarrow P(E\cup E^C)=P(\Omega)\\
			&\Rightarrow P(E)+P(E^C)=1\\
			&\Rightarrow P(E^C)=1-P(E)\qedhere
		\end{align*}
	\end{proof}
	\item $\forall E,F\in\mathscr{F}\quad E\subseteq F\Rightarrow P(E)\leq P(F)$
	\begin{proof}
		\begin{align*}
			F&=(F\cap E)\cup(F\cap E^C)\\
			&=E\cup(F\cap E^C)\\
			\Rightarrow P(F)&=P(E)+P(F\cap E^C)
		\end{align*}
		Essendo $P(F\cap E^C)\geq0$, segue la tesi.
	\end{proof}
	\item $\forall E,F\in\mathscr{F}\quad P(E\cup F)=P(E)+P(F)-P(E\cap F)$
	\begin{proof}
		Per definizione di misura di probabilità, $P$ è additiva su unioni disgiunte, quindi:
		\begin{align*}
			E\cup F&=E\cup (F\smallsetminus E)\\
			\Rightarrow P(E\cup F)&=P(E)+P(F\smallsetminus E)
		\end{align*}
		Ricordiamo che, per definizione:
		\begin{equation*}
			F\smallsetminus E=F\cap E^C
		\end{equation*}
		Inoltre:
		\begin{equation*}
			F=(F\cap E)\cup(F\cap E^C)
		\end{equation*}
		Sostituendo:
		\begin{align*}
			&F=(F\cap E)\cup(F\smallsetminus E)\\
			\Rightarrow &P(F)=P(F\cap E)+P(F\smallsetminus E)\\
			\Rightarrow &P(F\smallsetminus E)=P(F)-P(F\cap E)
		\end{align*}
		Sostituendo ancora:
		\begin{align*}
			P(E\cup F)&=P(E)+P(F\smallsetminus E)\\
			&=P(E)+P(F)-P(F\cap E)\qedhere
		\end{align*}
	\end{proof}
	\item La precedente si può generalizzare a una famiglia $\{E_n\}_n$ di eventi non necessariamente disgiunti:
	\begin{equation*}
		P(\bigcup_n E_n)\leq \sum_n P(E_n)
	\end{equation*}
	\item $P(E\cup F\cup G)=P(E)+P(F)+P(G)-P(E\cap F)-P(E\cap G)-P(F\cap G)+P(E\cap F\cap G)$
	\item $P(E\Delta F)=P(E)+P(F)-2P(E\cap F)$
\end{itemize}
Chiaramente, $P$ non è determinata univocamente da $\Omega$ e $\mathscr{F}$, però ci sono dei metodi "standard" per costruirla, soprattutto nelle applicazioni pratiche.
\subsubsection{Misura Empirica} % (fold)
\label{subs:misura_empirica}
Consideriamo una coppia $(\Omega,\mathscr{F})$ fissata in modo da rappresentare un esperimento ripetibile. Eseguendo l'esperimento $n$ volte si otterrà una sequenza di $n$ risultati
\begin{equation*}
	(\omega_1,...,\omega_n)\quad \omega_i\in\Omega\ \forall i\in\{1,...,n\}
\end{equation*}
Sia $E\in\mathscr{F}$, definiamo una quantità $n_E$ che rappresenti il numero di volte in cui $E$ si è verificato
\begin{equation*}
	n_E:=\lvert\{i\in\{1,...,n\}:\omega_i\in E\}\rvert
\end{equation*}
\begin{definizione}
	Si dice misura di probabilità empirica la funzione
	\begin{align*}
		\hat{P_n}:\mathscr{F}&\to[0,1]\\
		E&\mapsto\frac{n_E}{n}
	\end{align*}
\end{definizione}
Questa misura in modo empirico il numero di volte in cui un dato evento si è verificato. Il limite più importante è che l'esperimento deve essere ripetibile.
% subsubsection misura_empirica (end)
\subsubsection{Spazio campionario discreto} % (fold)
\label{subs:spazio_campionario_discreto}
Nel caso in cui $\Omega$ sia discreto e $\mathscr{F}=\mathds{P}(\Omega)$, si può dimostrare che per identificare univocamente $P$ è sufficiente identificare i valori $p_\omega$ tali che
\begin{equation*}
	p_\omega=P(\{\omega\})\quad\text{con }\sum_{\omega\in\Omega}p_\omega=1
\end{equation*}
Segue dalla \sigma-additività di $P$ che:
\begin{equation*}
	P(E)=\sum_{\omega\in E} p_\omega\quad\forall E\in\mathscr{F}
\end{equation*}
Si ricava che se $\Omega$ è finito
\begin{equation*}
	\Omega=\{\omega_1,...,\omega_n\}
\end{equation*}
identificare $P$ equivale ad identificare una famiglia
\begin{equation*}
	\{p_1,...,p_n\}
\end{equation*}
tale che 
\begin{equation*}
	\sum_{i=1}^n p_i=1
\end{equation*}
\begin{osservazione}
	In realtà sono sufficienti $n-1$ valori $p_i$, perché vale necessariamente:
	\begin{equation*}
		p_n=1-\sum_{i=1}^{n-1}p_i
	\end{equation*}
\end{osservazione}
Se invece $\Omega$ è numerabile, identificare $P$ equivale ad identificare una successione $(p_n)_n$ tale che
\begin{equation*}
	\sum_{i=1}^{+\infty}p_i=1
\end{equation*}
% subsubsection spazio_campionario_discreto (end)
\subsubsection{Probabilità Uniforme} % (fold)
\label{subs:probabilità_uniforme}
Un caso particolare del punto precedente si ha se $\Omega$ è finito e tutti gli eventi elementari hanno la stessa probabilità:
\begin{definizione}
	Sia $\Omega$ spazio di probabilità finito, la funzione di probabilità uniforme è la misura di probabilità identificata dalla famiglia di valori $p_i$ tali che:
	\begin{equation*}
		p_i=\frac{1}{n}\quad\forall i\in\{1,...,n\}
	\end{equation*}
\end{definizione}
In questo caso, vale che dato un evento $E\in\mathscr{F}:$
\begin{align*}
	P(E)&=\sum_{\omega\in E} P(\{\omega\})\\
	&=\sum_{\omega\in E} p_\omega\\
	&=\sum_{\omega\in E} \frac{1}{n}\\
	&=\frac{1}{n}*\sum_{\omega\in E} 1\\
	&=\frac{1}{n}*\lvert E\rvert\\
	&=\frac{\lvert E\rvert}{\lvert\Omega\rvert}
\end{align*}
In altre parole, la probabilità di un evento $E$ è pari al numero di risultati favorevoli ad $E$ diviso per il numero totale di risultati.
% subsubsection probabilità_uniforme (end)
% subsection misura_di_probabilità (end)
% section spazio_di_probabilità (end)
\section{Approfondimenti sulla Probabilità} % (fold)
\label{sec:approfondimenti_sulla_probabilità}
\subsection{Principio Fondamentale del Conteggio} % (fold)
\label{sub:principio_fondamentale_del_conteggio}
\begin{principio}[Fondamentale del Conteggio]
	Dovendo eseguire $R$ scelte consecutive tali che
	\begin{enumerate}
		\item $\forall r\in\{1,...,R\}$ la scelta va eseguita fra $n_r$ elementi
		\item $\forall r\in\{1,...,R\}$ la scelta non dipende dalle precedenti
		\item da due successioni distinte di $R$ scelte si giunge a risultati diversi
	\end{enumerate}
	Il numero totale di risultati possibili è
	\begin{equation*}
		\prod_{i=1}^R n_i
	\end{equation*}
\end{principio}
In generale, i problemi in cui interviene il principio fondamentale del conteggio riguardano il campionamento, secondo uno schema riconducibile all'estrazione di $k$ palline da un'urna che ne contiene $n$. Ci sono due possibilità riguardo le palline, ed altrettante riguardo l'estrazione:
\begin{itemize}
	\item Per quanto riguarda le palline, possono essere:
	\begin{itemize}
		\item tutte diverse (e quindi, virtualmente numerabili da $1$ a $n$)
		\item diverse a gruppi (con $m<n$ gruppi)
	\end{itemize}
	\item Per quanto riguarda l'estrazione, può essere:
	\begin{itemize}
		\item con reinserimento (con la possibilità di estrarre $k\in\mathbb{N}$ palline)
		\item senza reinserimento (limitando il numero di estrazioni a $k\leq n$)
	\end{itemize}
\end{itemize}
Inoltre è possibile distinguere fra due possibilità sugli aspetti interessanti delle palline estratte:
\begin{itemize}
	\item ci interessa la disposizione delle palline estratte (cioè ci interessa quali palline sono estratte e in quale ordine)
	\item ci interessa la combinazione delle palline estratte (cioè ci interessa solo quali palline sono estratte, ma non in quale ordine, e quindi ci interessa quante palline di ciascun tipo sono state estratte)
\end{itemize}
I problemi si possono quindi analizzare in base alle loro caratteristiche attraverso il calcolo combinatorio.
\paragraph{Disposizione con reinserimento} % (fold)
\label{par:disposizione_con_reinserimento}
In questo caso, assumendo che le palline siano tutte diverse, ad ogni estrazione ci sono $n$ possibilità diverse di estrarre la pallina, e quindi le possibili disposizioni sono:
\begin{equation*}
	\underbrace{n\cdot n\cdot \ldots \cdot n}_{k \text{ volte}} = n^k
\end{equation*}
% paragraph disposizione_con_reinserimento (end)
\paragraph{Disposizione senza reinserimento} % (fold)
\label{par:disposizione_senza_reinserimento}
Problema molto simile al precedente, con la differenza che le palline non vengono reinserite nell'urna. Ad ogni estrazione il numero di palline che è possibile estrarre diminuisce di 1. Le possibili disposizioni sono:
\begin{equation*}
	n\cdot (n-1) \cdot \ldots\cdot(n-k+1) = \frac{n!}{(n-k)!}
\end{equation*}
Un caso particolare si ha quando $k=n$, cioè se vengono estratte tutte le palline dall'urna. In questo caso, le disposizioni sono:
\begin{equation*}
	\frac{n!}{(n-k)!}=\frac{n!}{(n-n)!}=\frac{n!}{0!}=n!
\end{equation*}
Queste si dicono permutazioni, in quanto sono modi diversi di disporre gli stessi elementi.
% paragraph disposizione_senza_reinserimento (end)
\paragraph{Combinazioni senza reinserimento} % (fold)
\label{par:combinazioni_senza_reinserimento}
Anche in questo caso ad ogni estrazione il numero di palline che è possibile estrarre diminuisce di 1; inoltre, data una sequenza di palline estratte, questa è equivalente a tutte le sue permutazioni. Il numero di combinazioni si può quindi ottenere dividendo il numero di disposizioni ottenibili in questa situazione per il numero di permutazioni possibili della sequenza estratta:
\begin{equation*}
	\frac{n!}{(n-k)!\cdot k!}=\binom{n}{k}
\end{equation*}
Per convenzione si pone:
\begin{equation*}
	\binom{0}{0}=\binom{n}{0}=\binom{n}{n}=1
\end{equation*}
Un'applicazione importante del coefficiente binomiale è la formula del binomio di Newton:
\begin{equation*}
	(a+b)^n=\sum_{k=0}^n \binom{n}{k} a^k b^{n-k}
\end{equation*}
Alcune proprietà sono:
\begin{align*}
	2^n&=\sum_{k=0}^n \binom{n}{k}\\
	\binom{n}{k}&=\binom{n}{n-k}\\
	\binom{n}{k}&=\binom{n-1}{k}+\binom{n-1}{k-1}
\end{align*}
% paragraph combinazioni_senza_reinserimento (end)
\paragraph{Permutazioni con palline uguali} % (fold)
\label{par:permutazioni_con_palline_uguali}
Nel caso i colori siano $m<n$, e ci siano $n_i$ palline dell'$i$-esimo colore, il numero di modi di estrarle tutte si può ottenere dividendo il numero di modi di estrarre tutte le palline se fossero tutte diverse per il numero di modi di scambiare fra di loro le palline uguali:
\begin{equation*}
	\frac{n!}{n_1!\cdot n_2!\cdot\ldots\cdot n_m!}
\end{equation*}
Questo caso corrisponde al trovare il numero di anagrammi di una parola con lettere ripetute.
% paragraph permutazioni_con_palline_uguali (end)
% subsection principio_fondamentale_del_conteggio (end)
\subsection{Probabilità Condizionata} % (fold)
\label{sub:probabilità_condizionata}
Finora abbiamo visto situazioni in cui la probabilità di un dato evento $E$ dipende esclusivamente da $E$, cioè in cui la misura di quanto verosimile sia $E$ è basata solo sulle caratteristiche "di partenza" dello spazio di probabilità. In alcuni casi, è utile valutare come varia la probabilità di $E$ se sono fornite informazioni aggiuntive; l'obiettivo è formalizzare il concetto molto intuitivo che, ad esempio, la probabilità che piova quando è sereno è diversa dalla probabilità che piova quando è nuvoloso. In particolare, l'informazione relativa al clima deve avere un effetto sulla probabilità che piova. Questo viene formalizzato introducendo la misura di probabilità condizionata:
\begin{definizione}
	Sia $(\Omega,\mathscr{F},P)$ uno spazio di probabilità, sia $F\in\mathscr{F}$ tale che $P(F)>0$; si definisce misura di probabilità condizionata a $F$ la funzione
	\begin{align*}
		P(\cdot|F):\mathscr{F}&\to[0,1]\\
		E&\mapsto P(E|F)
	\end{align*}
	dove:
	\begin{equation*}
		P(E|F)=\frac{P(E\cap F)}{P(F)}\quad \forall E\in\mathscr{F}
	\end{equation*}
\end{definizione}
La probabilità $P(E|F)$ misura la probabilità che se si verifica $F$, si verifichi anche $E$. Si dimostra che la misura di probabilità condizionata $P(\cdot|F)$è effettivamente una misura di probabilità:
\begin{proof}
	\begin{enumerate}
		\item 
		\begin{align*}
			P(\Omega|F)&=\frac{P(\Omega\cap F)}{P(F)}\\
			&=\frac{P(F)}{P(F)}=1
		\end{align*}
		\item Considerando una famiglia $\{E_n\}_n$ di sottoinsiemi di $\Omega$:
		\begin{align*}
			P\left(\left.\bigcup_n E_n\right|F \right)&=\frac{P\left(\left(\bigcup_n E_n\right)\cap F\right)}{P(F)}\\
			&=\frac{P\left(\bigcup_n (E_n\cap F)\right)}{P(F)}\\
			&=\sum_n \frac{P(E_n\cap F)}{P(F)}
		\end{align*}
	\end{enumerate}
	\qedhere
\end{proof}
\begin{nota}
	Chiaramente, ha senso considerare la probabilità di $E$ condizionata a $F$ solo se $P(F)>0$.
\end{nota}
Alcune proprietà:
\begin{itemize}
	\item $P(E^C|F)=1-P(E|F)\quad\forall E\in\mathscr{F}$
	\item $E\cap F=\emptyset \Rightarrow P(E|F)=0$
	\item $F\subseteq E \Rightarrow P(E|F)=1$
	\item $P(E)=0 \Rightarrow P(E|F)=0$
	\item $P(E)=1 \Rightarrow P(E|F)=1$
	\item \textit{Formula di moltiplicazione}: sia $\{E_n\}_n$ una famiglia di eventi non necessariamente disgiunti, allora vale
	\begin{align*}
		P\left(\bigcap_{i=1}^n E_i\right)&=P\left(E_n|\bigcap_{i=1}^{n-1} E_i\right)\cdot\ldots\cdot P(E_1)\\
		&=\prod_{k=2}^n P\left(E_k|\bigcap_{i=1}^{k-1} E_i\right)\cdot P(E_1)
	\end{align*}
	\item Dalla precedente, per $n=2$, si ricava
	\begin{equation*}
		P(E\cap F)=P(E|F)\cdot P(F)
	\end{equation*}
\end{itemize}
\begin{nota}
	Nel contesto della probabilità condizionata, $P(E)$ si dice anche probabilità a priori di $E$, mentre $P(E|F)$ è detta, per contrasto, probabilità a posteriori.
\end{nota}
Vediamo adesso alcune formule legate alla probabilità condizionata.
\paragraph{Formula di Probabilità Totale} % (fold)
\label{par:formula_di_probabilità_totale}
Partendo dalla formula di moltiplicazione:
\begin{align*}
	P(E\cap F)&=P(E|F)\cdot P(F)\\
	P(E\cap F^C)&=P(E|F^C)\cdot P(F^C)
\end{align*}
$E\cap F$ e $E\cap F^C$ sono eventi disgiunti, e vale $(E\cap F)\cup(E\cap F^C)=E$. Segue:
\begin{align*}
	P(E)&=P(E\cap F)+P(E\cap F^C)\\
	&=P(E|F)P(F)+P(E|F^C)P(F^C)
\end{align*}
Questa formula si può generalizzare: consideriamo una partizione $\{F_n\}_n$ di $\Omega$, cioè una famiglia di sottoinsiemi di $\Omega$ tale che
\begin{align*}
	\bigcup_i F_i&=\Omega\\
	F_i\cap F_j&=\emptyset\quad\forall i\neq j
\end{align*}
Inoltre, imponiamo che
\begin{equation*}
	P(F_i)>0\quad\forall i
\end{equation*}
Allora, dato un evento $E\in\mathscr{F}$ si può scrivere:
\begin{equation*}
	P(E)=\sum_{i=1}^n P(E|F_i)\cdot P(F_i)
\end{equation*}
\begin{proof}
	Essendo $\{F_n\}_n$ una partizione di $\Omega$, vale:
	\begin{align*}
		E&=\bigcup_{i=1}^n (E\cap F_i)\\
		\Rightarrow P(E)&=P\left(\bigcup_{i=1}^n (E\cap F_i)\right)\\
		&=\sum_{i=1}^n P(E\cap F_i)\\
		&=\sum_{i=1}^n \frac{P(E\cap F_i)}{P(F_i)}P(F_i)\\
		&=\sum_{i=1}^n P(E|F_i)P(F_i)\qedhere
	\end{align*}
\end{proof}
% paragraph formula_di_probabilità_totale (end)
\paragraph{Formula di Bayes} % (fold)
\label{par:formula_di_bayes}
La formula di Bayes segue da un'interpretazione della formula di probabilità totale: ciascuno degli eventi $F_i$ si può interpretare come una possibile causa di $E$. Ciascuno degli addendi $P(E|F_i)P(F_i)$ rappresenta la probabilità che $E$ si verifichi dopo che si è verificato $F_i$. Ci chiediamo ora quale sia la probabilità che, avendo osservato che $E$ si verifica, si sia verificato $F_i$. Applicando le formule di moltiplicazione e di probabilità totale, considerando uno specifico evento $F_k$ della partizione, segue:
\begin{align*}
	P(F_k|E)&=\frac{P(F_k\cap E)}{P(E)}\\
&=\frac{P(E|F_k)P(F_k)}{\sum_{i=1}^n P(E|F_i)P(F_i)}
\end{align*}
\begin{esempio}
	Un'applicazione della formula di Bayes si ha in molti casi in cui si cerca di studiare un dato fenomeno non direttamente osservabile, e che quindi porta alla necessità di effettuare un test indiretto per valutare il presentarsi o meno del fenomeno. In modo semplificato, possiamo considerare che per l'evento ha $\{D,d\}$ come possibili outcome, rappresentanti rispettivamente il verificarsi o meno dell'evento, e il test ha $\{T,t\}$ come possibili risultati, che rappresentano rispettivamente il rilevare il verificarsi o il non verificarsi del fenomeno. Gli outcome dell'esperimento sono quindi:
	\begin{itemize}
		\item $TD$ se il test ha correttamente rilevato il verificarsi dell'esperimento
		\item $td$ se il test ha correttamente rilevato il non verificarsi dell'esperimento
		\item $Td$ se il test ha rilevato un falso positivo, detto anche errore di prima specie
		\item $tD$ se il test ha rilevato un falso negativo, detto anche errore di seconda specie
	\end{itemize}
	Due probabilità che caratterizzano l'esperimento sono:
	\begin{itemize}
		\item $P(T|D)$, detta sensibilità
		\item $P(t|d)$, detta specificità
	\end{itemize}
	In particolare, date queste probabilità, è possibile ricavare quanto probabile sia che il fenomeno si sia verificato dopo aver ricevuto un risultato positivo al test:
	\begin{equation*}
		P(D|T)=\frac{P(T|D)P(D)}{P(T|D)P(D)+P(T|d)P(d)}%BAYES
	\end{equation*}
\end{esempio}
% paragraph formula_di_bayes (end)
% subsection probabilità_condizionata (end)
\subsection{Indipendenza} % (fold)
\label{sub:indipendenza}
\begin{definizione}
	Dati due eventi $E,F\in\mathscr{F}$, $E$ e $F$ si dicono indipendenti, e si indica
	\begin{equation*}
		E\Bot F
	\end{equation*}
	se e solo se
	\begin{equation*}
		P(E\cap F)=P(E)P(F)
	\end{equation*}
\end{definizione}
Il concetto di eventi indipendenti formalizza l'idea che se due eventi sono completamente slegati, allora la probabilità che uno si verifichi non ha nessuna influenza sulla probabilità che si verifichi anche l'altro. Alcune proprietà:
\begin{itemize}
	\item $E\Bot \emptyset$
	\item $E\Bot\Omega$
	\item $E\Bot E\Leftrightarrow E=\Omega\vee E=\emptyset$
	\item Se $P(E)>0$ e $P(F)>0$, allora vale
	\begin{equation*}
		E\Bot F\Leftrightarrow P(E|F)=P(E) \Leftrightarrow P(F|E)=P(F)
	\end{equation*}
	\item $E\Bot F\Leftrightarrow E^C\Bot F\Leftrightarrow E\Bot F^C\Leftrightarrow E^C\Bot F^C$
\end{itemize}
Per tre eventi, la definizione di indipendenza è lievemente più complessa:
\begin{definizione}
	Dati tre eventi $E,F,G\in\mathscr{F}$, questi si dicono indipendenti se e solo se
	\begin{enumerate}
		\item
		\begin{equation*}
			E\Bot F\wedge E\Bot G\wedge F\Bot G
		\end{equation*}
		\item 
		\begin{equation*}
			P(E\cap F\cap G)=P(E)P(F)P(G)
		\end{equation*}
	\end{enumerate}
\end{definizione}
\begin{NB}
	Le due condizioni sono slegate: ci sono casi in cui gli eventi sono indipendenti a due a due, ma la loro intersezione non ha probabilità pari al prodotto delle singole probabilità, o viceversa la probabilità dell'intersezione coincide con il prodotto delle probabilità, ma gli eventi non sono indipendenti a due a due.
\end{NB}
Il concetto di indipendenza si estende a più eventi:
\begin{definizione}
	Data una famiglia finita di eventi $\{E_n\}_n\subseteq\mathscr{F}$, si dice famiglia di eventi indipendenti se e solo se $\forall r\in \{2,3,...,n\}$ ogni sottofamiglia di $\{E_n\}_n$ composta da $r$ eventi è indipendente.
\end{definizione}
Le due condizioni continuano ad essere slegate. Si nota che il numero di casi da considerare aumenta quadraticamente al crescere del numero di eventi.
\begin{definizione}
	Data una famiglia numerabile di eventi $\{E_n\}_n\subseteq\mathscr{F}$, si dice famiglia di eventi indipendenti se $\forall \{F_k\}_k\subseteq\{E_n\}_n$ con $\{F_k\}_k$ famiglia finita, $\{F_k\}_k$ è famiglia di eventi indipendenti.
\end{definizione}
\begin{osservazione}
	Se $\{A_n\}_n$ è una famiglia di eventi indipendenti (non importa quanti), allora anche la famiglia formata sostituendo alcuni (non necessariamente tutti) eventi con i rispettivi complementari è indipendente.
\end{osservazione}
\begin{esercizio}
	Dimostrare che se $\{A,B\}$ sono indipendenti, anche $\{A^C,B^C\}$ sono indipendenti
	\begin{soluzione}
		\begin{align*}
			P(A^C\cap B^C)&=P((A\cup B)^C)\\
			&=1-P(A\cup B)\\
			&=1-P(A)-P(B)+P(A\cap B)\\
			&=1-P(A)+1-P(B)+P(A)P(B)-1\\
			&=P(A^C)+P(B^C)+(1-P(A^C))(1-P(B^C))-1\\
			&=\cancel{P(A^C)}+\cancel{P(B^C)}+\cancel{1}-\cancel{P(A^C)}-\cancel{P(B^C)}+P(A^C)P(B^C)-\cancel{1}\\
			&=P(A^C)P(B^C)\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
\begin{esercizio}
	A tre studenti viene posta la stessa domanda. Sappiamo che il primo risponde correttamente con probabilità $\frac{1}{2}$, il secondo con probabilità $\frac{2}{3}$, il terzo con probabilità $\frac{1}{3}$. Gli studenti non possono comunicare fra loro. Vogliamo calcolare la probabilità che, se un solo studente ha risposto correttamente, sia stato il secondo.
	\begin{soluzione}
		Consideriamo gli eventi relativi ai possibili outcome di cui ci può interessare:
		\begin{align*}
			S_i&=\text{"l'$i$-esimo studente ha risposto correttamente"}\\
			E_i&=\text{"ci sono state $i$ risposte esatte"}
		\end{align*}
		Siccome è noto che solo uno studente ha risposto correttamente, la probabilità da calcolare è la probabilità di $S_2$ condizionato a $E_1$:
		\begin{equation*}
			P(S_2|E_1)=\frac{P(S_2\cap E_1)}{P(E_1)}
		\end{equation*}
		Concettualmente, possiamo riscrivere $S_2\cap E_1$ ed $E_1$ come unioni ed intersezioni di eventi più semplici:
		\begin{equation*}
			P(S_2|E_1)=\frac{P(S_2\cap E_1)}{P(E_1)}=\frac{P(S_1^C\cap S_2\cap S_3^C)}{P((S_1\cap S_2^C\cap S_3^C)\cup(S_1^C\cap S_2\cap S_3^C)\cup(S_1^C\cap S_2^C\cap S_3))}
		\end{equation*}
		Siccome gli eventi parte dell'unione sono disgiunti, la probabilità si può distribuire:
		\begin{equation*}
			P(S_2|E_1)=\frac{P(S_2\cap E_1)}{P(E_1)}=\frac{P(S_1^C\cap S_2\cap S_3^C)}{P(S_1\cap S_2^C\cap S_3^C)+P(S_1^C\cap S_2\cap S_3^C)+P(S_1^C\cap S_2^C\cap S_3)}
		\end{equation*}
		Siccome gli studenti non possono comunicare, la risposta di ciascuno non influenza la risposta degli altri, e quindi possiamo assumere che i tre eventi siano indipendenti:
		\begin{align*}
			&\frac{P(S_1^C\cap S_2\cap S_3^C)}{P(S_1\cap S_2^C\cap S_3^C)+P(S_1^C\cap S_2\cap S_3^C)+P(S_1^C\cap S_2^C\cap S_3)}\\
			&=\frac{P(S_1^C)P(S_2)P(S_3^C)}{P(S_1)P(S_2^C)P(S_3^C)+P(S_1^C)P(S_2)P(S_3^C)+P(S_1^C)P(S_2^C)P(S_3)}\\
			&=\frac{P(\frac{1}{2})P(\frac{2}{3})P(\frac{2}{3})}{P(\frac{1}{2})P(\frac{1}{3})P(\frac{2}{3})+P(\frac{1}{2})P(\frac{2}{3})P(\frac{2}{3})+P(\frac{1}{2})P(\frac{1}{3})P(S_3)}~0.57\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
\subsubsection{Schema di Bernoulli} % (fold)
\label{ssub:schema_di_bernoulli}
Detto anche \textit{Modello Binomiale per Eventi}. Consideriamo un esperimento con queste caratteristiche:
\begin{itemize}
	\item Vengano eseguite $n$ prove identiche, effettuate in sequenza
	\item Ciascuna prova ha solo due possibili risultati, che generalmente si indicano con $\{0,1\}$
	\item Il risultato di ciascuna prova non influenza il risultato di nessuna delle altre
\end{itemize}
L'esperimento si può descrivere con un modello di probabilità dato da $\Omega=\{0,1\}^n$, $\mathscr{F}=\mathds{P}(\Omega)$, e da una misura di probabilità $P$ che rispetti le condizioni:
\begin{itemize}
	\item Gli eventi
	\begin{equation*}
		B_j=\{(b_1,...,b_n)|b_j=1\}
	\end{equation*}
	sono equiprobabili, cioè
	\begin{equation*}
		P(B_j)=p\quad\forall j\in\{1,...,n\}\text{ con }p\in[0,1]
	\end{equation*}
	\item La famiglia
	\begin{equation*}
		\{B_1,...,B_n\}
	\end{equation*}
	è una famiglia di eventi indipendenti.
\end{itemize}
\begin{esempio}
	Consideriamo un sistema di comunicazione formato da $n$ componenti, ciascuno dei quali ha probabilità $p$ di funzionare. Nella sua totalità, il sistema funziona se almeno metà delle componenti funzionano. Ci chiediamo per quali valori di $p$ un sistema a tre componenti ha maggiore probabilità di funzionare rispetto a un sistema formato da un solo componente.
	\begin{soluzione}
		L'idea è di rappresentare il problema attraverso lo schema di Bernoulli. Identifichiamo:
		\begin{itemize}
			\item una prova con il test di un componente
			\item il numero di prove ripetute con il numero di componenti
			\item gli esiti $\{0,1\}$ con $\{"funziona","non\ funziona"\}$ come
			\begin{align*}
				"funziona"&\mapsto1\\
				"non\ funziona"&\mapsto0
			\end{align*}
			\item la probabilità di successo con $P(B_j)=p$
		\end{itemize}
		Per il sistema a $3$ componenti vale:
		\begin{align*}
			&P(\text{"sistema funziona"})\\
			&=P(\text{"almeno due componenti su tre funzionano"})\\
			&=P(\{\text{"esattamente 2 componenti funzionano"}\}\cup\{\text{"esattamente 3 componenti funzionano"}\})\\
			&=P(\{\text{"2 componenti su 3 funzionano"}\})+P(\{\text{"tutti e 3 i componenti funzionano"}\})\\
			&=P(\bigcup_{I\subset\{1,2,3\}\wedge \lvert I\rvert=2}\{(b_1,b_2,b_3)\in\{0,1\}^3|b_j=1\Leftrightarrow j\in I\})+P(\{(1,1,1)\})\\
			&\text{essendo gli eventi nell'unione disgiunti:}\\
			&=\sum_{I\subset\{1,2,3\}\wedge \lvert I\rvert=2}P(\{(b_1,b_2,b_3)\in\{0,1\}^3|b_j=1\Leftrightarrow j\in I\})+P(\{(1,1,1)\})\\
			&=\sum_{I\subset\{1,2,3\}\wedge \lvert I\rvert=2}\prod_{j\in I}P(B_j)\cdot\prod_{j\notin I}P(B_j^C)+P(\{(1,1,1)\})\\
			&\text{siccome }\lvert I\rvert=2\text{:}\\
			&=\sum_{I\subset\{1,2,3\}\wedge \lvert I\rvert=2}p^2 (1-p)+p^3\\
			&=\binom{3}{2}p^2 (1-p)+p^3\\
			&=3\cdot p^2 (1-p)+p^3
		\end{align*}
		Per il sistema ad una componente, chiaramente vale:
		\begin{equation*}
			P(\text{"sistema funziona"})=p
		\end{equation*}
		Quindi dobbiamo cercare $p$ tale che:
		\begin{align*}
			&3\cdot p^2 (1-p)+p^3>p\\
			\Leftrightarrow&3p^2-2p^3>p\\
			\Leftrightarrow&p>\frac{1}{2}
		\end{align*}
		Nel complesso, si ottiene che ha senso usare più componenti solo se ciascuna ha più probabilità di funzionare di $\frac{1}{2}$.
	\end{soluzione}
\end{esempio}
% subsubsection schema_di_bernoulli (end)
% subsection indipendenza (end)
% section approfondimenti_sulla_probabilità (end)
\section{Variabili Aleatorie Discrete} % (fold)
\label{sec:variabili_aleatorie_discrete}
\subsection{Concetti Base per le Variabili Aleatorie} % (fold)
\label{sub:concetti_base_per_le_variabili_aleatorie}
Spesso, negli esperimenti concreti ha senso raccogliere i dati attraverso dei costrutti che si possano analizzare più approfonditamente degli spazi di probabilità.
\begin{definizione}
	Sia $(\Omega, \mathds{P}(\Omega), P)$ spazio di probabilità discreto. Si dice variabile aleatoria una mappa (funzione)
	\begin{equation*}
		X\colon \Omega\to\mathds{R}
	\end{equation*}
\end{definizione}
\begin{definizione}
	Data una variabile aleatoria $X$ si dice alfabeto di $X$ e si indica $\mathcal{X}$ l'immagine di $\Omega$ rispetto $X$:
	\begin{equation*}
		\mathcal{X}=\{x\in\mathds{R}\vert \exists \omega\in\Omega\colon X(\omega)=x\}
	\end{equation*}
\end{definizione}
\begin{nota}
	Dato uno spazio di probabilità ci sono infinite variabili aleatorie associate.
\end{nota}
Per un dato spazio di probabilità $(\Omega, \mathds{P}(\Omega), P)$ e un evento $E\in\mathds{P}(\Omega)$, una variabile aleatoria che si può sempre definire è detta variabile aleatoria indicatrice, ed è definita come:
\begin{equation*}
	\mathds{1}_E(\omega)=
	\begin{cases}
		1&\text{ se }\omega\in E\\
		0&\text{ se }\omega\notin E\\
	\end{cases}
\end{equation*}
\begin{osservazione}
	Le variabili aleatorie sono funzioni a valori reali, quindi se sono definite sullo stesso $\Omega$ si possono combinare attraverso le consuete operazioni aritmetiche fra reali.
\end{osservazione}
Possiamo assegnare ad un certo alfabeto $\mathcal{X}$ una probabilità, asegnando ai singoletti di $\mathcal{X}$ (cioè ai suoi sottoinsiemi di cardinalità $1$) una probabilità $P^X$ che sia compatibile con la misura di probabilità $P$ dello spazio di probabilità su cui è definita $X$. Per farlo, consideriamo gli eventi definiti da
\begin{equation*}
	E_k=\{\omega\in\Omega|X(\omega)=x_k\}=X^{-1}(x_k)
\end{equation*}
Siccome $X$ è una funzione, questi eventi sono disgiunti e la loro unione è $\Omega$ (perché per definizione di funzione \uline{ogni} $\omega\in\Omega$ viene mappato in \uline{uno e un solo} $x_k\in\mathcal{X}$), quindi formano una partizione di $\Omega$. Possiamo definire la probabilità $P^X$ come $P$ calcolata sugli eventi $E_k$:
\begin{definizione}
	Sia $X$ variabile aleatoria sullo spazio di probabilità $(\Omega,\mathds{P}(\Omega,P)$. Si dice misura di probabilità indotta la funzione
	\begin{align*}
		P^X&\to [0,1]\\
		\{x_k\}&\mapsto P^X(\{x_k\})=P(X^{-1}(x_k))
	\end{align*}
\end{definizione}
$X^{-1}(x_k)$ è l'insieme degli eventi elementari che $X$ mappa in $x_k$, quindi $P^X(\{x_k\})$ rappresenta la probabilità che l'esito dell'esperimento venga mappato nel numero $x_k$ da $X$. In altre parole, $P^X(\{x_k\})$ rappresenta la probabilità dell'evento "si verifica un esito che viene mappato in $x_k$ da $X$".
\begin{lemma}
	La misura di probabilità indotta è una misura di probabilità, definita sullo spazio campionario $\mathcal{X}$ e sulla \sigma-algebra $\mathds{P}(\mathcal{X})$.
\end{lemma}
In generale, vorremmo fosse possibile definire una variabile aleatoria indipendentemente dall'esperimento da cui deriva, cioè vorremmo dare una descrizione probabilistica di $X$ che non sia basata sullo spazio di probabilità $(\Omega, \mathds{P}(\Omega),P)$. È sempre possibile mostrare i valori che $X$ può assumere mostrando il suo alfabeto, ma con gli strumenti introdotti finora non è possibile caratterizzare la probabilità che assuma ciascun valore; abbiamo introdotto la probabilità indotta, che però è ancorata nello spazio di probabilità sottostante a $X$. Per separare $X$ da $\Omega$ introduciamo la densità di probabilità.
\begin{definizione}
	Sia $X$ variabile aleatoria con alfabeto $\mathcal{X}$, e sia $P^X$ la sua probabilità indotta. Si dice densità di probabilità di $X$ la funzione
	\begin{align*}
		p_X:X&\to[0,1]\\
		x_k&\mapsto p_X(x_k)=P^X(\{x_k\})
	\end{align*}
\end{definizione}
\begin{esercizio}
	Lancio una moneta e un dado; se i risultati che ottengo hanno la stessa iniziale vinco 1€, altrimenti perdo 50cents. Sia $X$ la variabile aleatoria che descrive la vincita o la perdita. Determinare alfabeto e densità di X.
	\begin{soluzione}
		L'alfabeto è
		\begin{equation*}
			\mathcal{X}=\{1,-\frac{1}{2}\}
		\end{equation*}
		Per identificare la densità discreta è necessario identificare lo spazio campionario:
		\begin{equation*}
			\Omega=\{(x,y)|x\in\{T,C\}, y\in\{1,2,3,4,5,6\}\}
		\end{equation*}
		Si ricava:
		\begin{equation*}
			p_X(1)=P(X^{-1}(1))=P(\{(T,3),(C,5)\})=\frac{2}{12}
		\end{equation*}
		Notando che $X=-\frac{1}{2}\Leftrightarrow X\neq 1$:
		\begin{equation*}
			p_X(-\frac{1}{2})=P(X^{-1}(-\frac{1}{2}))=P(\{(T,3),(C,5)\}^C)=1-\frac{2}{12}=\frac{10}{12}\qedhere
		\end{equation*}
	\end{soluzione}
\end{esercizio}
Si nota che alfabeto e densità di una variabile aleatoria non identificano l'esperimento originale. Mentre è sempre possibile, dato lo spazio di probabilità, ricavare la variabile aleatoria e la misura di probabilità indotta, molto più di frequente viene data direttamente la variabile aleatoria, caratterizzandola attraverso il suo alfabeto e la sua densità discreta:
\begin{definizione}
	Sia $X$ una variabile aleatoria, questa può essere definita indicando:
	\begin{itemize}
		\item il suo alfabeto $\mathcal{X}$
		\item la sua densità discreta $p_X(x_k)$ $\forall x_k\in\mathcal{X}$
	\end{itemize}
	Questa si dice definizione o descrizione probabilistica di $X$.
\end{definizione}
\begin{esercizio}
	Estraiamo 3 carte da un mazzo di 52. Vinciamo 1€ pero ogni carta di picche estratta. Sia $X$ la variabile aleatoria che descrive la vincita; determinarne alfabeto e densità.
	\begin{soluzione}
		L'alfabeto è:
		\begin{equation*}
			\mathcal{X}=\{0,1,2,3\}
		\end{equation*}
		La densità si ricava dall'esperimento:
		\begin{align*}
			p_X(0)=P(X^{-1}(0))&=P(\text{"non sono estratte carte di picche"})\\
			&=\frac{\binom{39}{3}}{\binom{52}{3}}=\frac{703}{1700}\\
			p_X(1)=P(X^{-1}(1))&=P(\text{"è estratta una sola carta di picche"})\\
			&=\frac{13\cdot\binom{39}{2}}{\binom{52}{3}}=\frac{741}{1700}\\
			p_X(2)=P(X^{-1}(2))&=P(\text{"sono estratte due carte di picche"})\\
			&=\frac{\binom{13}{2}\cdot39}{\binom{52}{3}}=\frac{234}{1700}\\
			p_X(3)=P(X^{-1}(3))&=P(\text{"sono estratte tre carte di picche"})\\
			&=\frac{\binom{13}{3}}{\binom{52}{3}}=\frac{22}{1700}\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
A volte ha senso comporre una variabile aleatoria con una funzione reale, ottenendo un'altra variabile aleatoria. Vediamo un esempio:
\begin{esempio}
	Sia $X$ variabile aleatoria con alfabeto
	\begin{equation*}
		\mathcal{X}=\{-1,1,3\}
	\end{equation*}
	e densità discreta
	\begin{align*}
		p_X(-1)&=p_X(3)=\frac{1}{4}\\
		p_x(1)&=\frac{1}{2}
	\end{align*}
	Caratterizziamo $Y=g(X)=X^2$, che è data dalla composizione di $X$ e la funzione
	\begin{align*}
		g:\mathds{R}&\to\mathds{R}\\
		x&\mapsto x^2
	\end{align*}
	L'alfabeto di $Y$ è dato dall'applicazione di $g$ a tutti gli elementi di $\mathcal{X}$:
	\begin{equation*}
		\mathcal{Y}=\{1,9\}
	\end{equation*}
	Per calcolare la densità discreta di $Y$ bisogna ricondurre il problema alla variabile X:
	\begin{align*}
		p_Y(1)&=P(X^{-1}(-1)\cup X^{-1}(1))\\
		&=P(X^{-1}(-1))+P(X^{-1}(1))\\
		&=p_X(-1)+p_X(1)=\frac{3}{4}\\
		p_Y(9)&=P(X^{-1}(3))\\
		&=p_X(3)=\frac{1}{4}
	\end{align*}
\end{esempio}
Questo concetto si formalizza:
\begin{definizione}
	Siano $X:\Omega\to\mathds{R}$ variabile aleatoria e $g:\mathds{R}\to\mathds{R}$ funzione reale di variabile reale. Si dice funzione di $X$ la composizione $Y=g\circ X$, la quale è ancora una variabile aleatoria caratterizzata da
	\begin{itemize}
		\item Un alfabeto, il quale è l'immagine di $\mathcal{X}$ attraverso $g$:
		\begin{equation*}
			\mathcal{Y}=g(\mathcal{X})
		\end{equation*}
		\item Una densità discreta $p_Y$, tale che $p_Y(y_j)$ è la somma delle densità discrete di tutti i valori $x_i$ che $g$ associa a $y_j$:
		\begin{equation*}
			\forall y_i\in\mathcal{Y}\quad p_Y(y_j)=\sum_{x_i\in\{x_i|g(x_i)=y_j\}}p_X(x_i)
		\end{equation*}
	\end{itemize}
\end{definizione}
% subsection concetti_base_per_le_variabili_aleatorie (end)
\subsection{Valor Medio} % (fold)
\label{sub:valor_medio}
Il valor medio di una variabile aleatoria $X$ rappresenta il valore attorno a cui si distribuiscono i valori assunti da $X$.
\begin{definizione}
	Sia $X$ variabile aleatoria discreta con alfabeto $\mathcal{X}$ e densità di probabilità $p_X$. Il valor medio di $X$ è definito come:
	\begin{equation*}
		E(X)=\sum_{x_k\in\mathcal{X}} x_k\cdot p_X(x_k)
	\end{equation*}
\end{definizione}
Il valor medio ha anche molti altri nomi, fra cui media, speranza matematica, valore atteso, e molti altri.
\begin{osservazione}
	Se $X$ è discreta anche $\mathcal{X}$ lo è, ma non è detto che sia finito. Se è numerabile, il valor medio diventa la somma di una serie, la quale non è detto che esiste; se la serie non converge, il valor medio non esiste.
\end{osservazione}
Il valor medio si può intendere come il baricentro di un sistema formato da una serie di masse disposte su una sbarra, dove $x_k$ è il braccio della $k$-esima massa e $p_X(x_k)$ è il suo peso.
\begin{teorema}[Fondamentale del valor medio]
	Sia $X:\Omega\to\mathds{R}$ variabile aleatoria discreta. Allora si ha
	\begin{equation*}
		E(X)=\sum_{\omega\in\Omega} X(\omega)\cdot P(\{\omega\})
	\end{equation*}
\end{teorema}
\begin{proof}
	\begin{align*}
		E(X)&=\sum_{x_k\in\mathcal{X}}x_kP(x_k)\\
		&=\sum_{x_k\in\mathcal{X}}x_kP(X^{-1}(x_k))\\
		&=\sum_{x_k\in\mathcal{X}}x_kP(\{\omega\in\Omega|X(\omega)=x_k\})\\
		&=\sum_{x_k\in\mathcal{X}}\sum_{w:X(\omega)=x_k}x_kP(\{\omega\})\\
		&=\sum_{x_k\in\mathcal{X}}\sum_{w:X(\omega)=x_k}X(\omega)P(\{\omega\})
	\end{align*}
	Siccome al variare di $k$ gli insiemi $\{\omega|X(\omega)=x_k\}$ sono disgiunti, e i valori $x_k$ sono tutti scorsi dalla prima sommatoria, questi formano una partizione di $\Omega$, quindi le due sommatorie corrispondono ad un unica sommatoria su tutto $\Omega$ stesso:
	\begin{equation*}
		=\sum_{\omega\in\Omega}X(\omega)P(\{\omega\})\qedhere
	\end{equation*}
\end{proof}
Questo teorema nella pratica non è utilizzato, ma permette di dimostrare alcune proprietà importanti del valor medio: siano $X,Y:\Omega\to\mathds{R}$ variabili aleatorie, siano $a,b\in\mathds{R}$, allora valgono
\begin{enumerate}
	\item Linearità: $E(aX+bY)=aE(X)+bE(Y)$
	\begin{enumerate}
		\item $E(aX)=aE(X)$
		\begin{proof}
			\begin{align*}
				aX:\Omega&\to\mathds{R}\\
				\omega&\mapsto aX(\omega)
			\end{align*}
			Per il teorema fondamentale:
			\begin{align*}
				E(X)&=\sum_{\omega\in\Omega} aX(\omega)\cdot P(\{\omega\})\\
				&=a\sum_{\omega\in\Omega} X(\omega)\cdot P(\{\omega\})\\
				&=aE(X)\qedhere
			\end{align*}
		\end{proof}
		\item $E(X+Y)=E(X)+E(Y)$
		\begin{proof}
			\begin{align*}
				X+Y:\Omega&\to\mathds{R}\\
				\omega&\mapsto X(\omega)+Y(\omega)
			\end{align*}
			Per il teorema fondamentale:
			\begin{align*}
				E(X)&=\sum_{\omega\in\Omega} (X(\omega)+Y(\omega))\cdot P(\{\omega\})\\
				&=\sum_{\omega\in\Omega} (X(\omega)\cdot P(\{\omega\})+Y(\omega)\cdot P(\{\omega\}))\\
				&=\sum_{\omega\in\Omega} X(\omega)\cdot P(\{\omega\})+\sum_{\omega\in\Omega} Y(\omega)\cdot P(\{\omega\})\\
				&=E(X)+E(Y)\qedhere
			\end{align*}
		\end{proof}
	\end{enumerate}
	\item Positività: se $X$ è una variabile aleatoria non negativa (cioè tale che $X\geq0$, cioè tale che $\mathcal{X}\subseteq\mathds{R}_+$, allora anche $E(X)$ è non negativo
	\begin{equation*}
		X\geq0\Rightarrow E(X)\geq0
	\end{equation*}
	\begin{proof}
		Per definizione:
		\begin{equation*}
			E(X)=\sum_{x_k\in\mathcal{X}} x_k\cdot p_X(x_k)
		\end{equation*}
		Per definizione:
		\begin{equation*}
			p_X(x_k)\geq0\quad\forall x_k\in\mathcal{X}
		\end{equation*}
		Per $Hp$:
		\begin{equation*}
			x_k\geq0\quad\forall x_k\in\mathcal{X}
		\end{equation*}
		Segue che i prodotti sono non negativi, e la sommatoria è a sua volta non negativa.
	\end{proof}
	\item Monotonia: $X\geq Y\Rightarrow E(X)\geq E(Y)$
	\begin{proof}
		Segue dalle altre proprietà:
		\begin{align*}
			X\geq Y&\Leftrightarrow X-Y\geq0\\
			\text{Per positività: }&\Leftrightarrow E(X-Y)\geq0\\
			\text{Per linearità: }&\Leftrightarrow E(X)-E(Y)\geq0\\
			&\Leftrightarrow E(X)\geq E(Y)\qedhere
		\end{align*}
	\end{proof}
	\item Limiti inferiore e superiore: essendo $\mathcal{X}$ discreto, ha limiti superiore e inferiore (che potrebbero essere infiniti); indichiamo
	\begin{align*}
		\underline{x}&=inf(\mathcal{X})\\
		\overline{x}&=sup(\mathcal{X})
	\end{align*}
	Allora:
	\begin{equation*}
		\underline{x}\leq E(X)\leq\overline{x}
	\end{equation*}
	\begin{proof}
		Per definizione:
		\begin{equation*}
			\underline{x}\leq x_k\leq\overline{x}\quad\forall x_k\in\mathcal{X}
		\end{equation*}
		Segue:
		\begin{align*}
			\sum_{x_k\in\mathcal{X}} \underline{x}\cdot p_X(x_k)&\leq\sum_{x_k\in\mathcal{X}} x_k\cdot p_X(x_k)\leq\sum_{x_k\in\mathcal{X}} \overline{x}\cdot p_X(x_k)\\
			\underline{x}\sum_{x_k\in\mathcal{X}} p_X(x_k)&\leq\sum_{x_k\in\mathcal{X}} x_k\cdot p_X(x_k)\leq\overline{x}\sum_{x_k\in\mathcal{X}} p_X(x_k)\\
			\underline{x}\cdot1&\leq\sum_{x_k\in\mathcal{X}} x_k\cdot p_X(x_k)\leq\overline{x}\cdot1
		\end{align*}
		Segue la tesi.
	\end{proof}
\end{enumerate}
\begin{osservazione}
	Se $a\in\mathds{R}$, vale sempre $E(a)=a$, perché possiamo vedere una costante come un valore assunto da una variabile aleatoria $X$ tale che $X(\omega)=a\ \forall\omega\in\Omega$, e quindi vale
	\begin{align*}
		\mathcal{X}&=\{a\}\\
		p_X(a)&=1
	\end{align*}
\end{osservazione}
\subsubsection{Valor Medio di una Funzione di una Variabile Aleatoria} % (fold)
\label{ssub:valor_medio_di_una_funzione_di_una_variabile_aleatoria}
Abbiamo visto che se $X$ è una variabile aleatoria e $g$ una funzione reale di variabile reale, possiamo definire la variabile aleatoria $Y=g\circ X$. Vogliamo ora calcolare $E(Y)$; per questo introduciamo un teorema (che non dimostriamo).
\begin{teorema}
	\begin{equation*}
		E(Y)=\sum_{x_k\in\mathcal{X}} g(x_k)\cdot p_X(x_k)
	\end{equation*}
\end{teorema}
Questo teorema ci permette di calcolare $E(Y)$ senza la necessità di caratterizzare completamente $Y$.
% subsubsection valor_medio_di_una_funzione_di_una_variabile_aleatoria (end)
% subsection valor_medio (end)
\subsection{Varianza} % (fold)
\label{sub:varianza}
Mentre il valor medio quantifica un valore attorno a cui i valori assunti da una variabile aleatoria si distribuiscono, la varianza quantifica la dispersione dei valori.
\begin{definizione}
	Sia $X$ variabile aleatoria di alfabeto $\mathcal{X}$ e densità $p_X$; la varianza di $X$ si indica con $Var(X)$, ed è definita come
	\begin{equation*}
		Var(X)=\sum_{x_k\in\mathcal{X}}(x_k-E(X))^2p_X(x_k)
	\end{equation*}
\end{definizione}
\begin{esempio}
	Consideriamo le variabili aleatorie:
	\begin{align*}
		X_1&\in\{-1,\frac{1}{4},\frac{3}{4}\}\\
		p_{X_1}(-1)&=p_{X_1}(\frac{1}{4})=p_{X_1}(\frac{3}{4})=\frac{1}{3}\\
		X_2&\in\{-10,10\}\\
		p_{X_2}(-10)&=p_{X_2}(10)=\frac{1}{2}
	\end{align*}
	Notiamo che
	\begin{align*}
		E(X_1)&=-1\cdot\frac{1}{3}+\frac{1}{4}\cdot\frac{1}{3}+\frac{3}{4}\cdot\frac{1}{3}=0\\
		E(X_2)&=-10\cdot\frac{1}{2}+10\cdot\frac{1}{2}=0
	\end{align*}
	Ma
	\begin{align*}
		Var(X_1)&=(-1)^2\cdot\frac{1}{3}+(\frac{1}{4})^2\cdot\frac{1}{3}+(\frac{3}{4})^2\cdot\frac{1}{3}\approx0.524\\
		Var(X_2)&=(-10)^2\cdot\frac{1}{2}+(10)^2\cdot\frac{1}{2}=100
	\end{align*}
\end{esempio}
\begin{osservazione}
	La varianza si può definire in funzione solo della media:
	\begin{equation*}
		Var(X)=E((X-E(X))^2)
	\end{equation*}
	Si può vedere considerando $Var(X)=E(g(X))$ con $g(x)=(x-E(X))^2$.
\end{osservazione}
Dall'osservazione possiamo ricavare alcuni risultati interessanti:
\begin{align*}
	Var(X)&=E((X-E(X))^2)\\
	&=E(X^2-2\cdot X\cdot E(X)+(E(X))^2)\\
	&\text{ricordando le proprietà del valor}\\
	&\text{medio, e ricordando che $E(a)=a$:}\\
	&=E(X^2)-2\cdot E(X)\cdot E(X)+(E(X))^2\\
	&=E(X^2)-(E(X))^2
\end{align*}
In molti testi questa è data come definizione di varianza. Dalla definizione si ricava che $Var(X)\geq 0$, quindi deve sempre valere $E(X^2)-(E(X))^2$. Vediamo alcune proprietà della varianza:
\begin{enumerate}
	\item $Var(X)\geq0$, e in particolare
	\begin{equation*}
		Var(X)=0\Leftrightarrow X=k\in\mathds{R}
	\end{equation*}
	\begin{proof}
		Segue immediatamente dalla difinizione.
	\end{proof}
	\item $Var(aX)=a^2\cdot Var(X)$
	\begin{proof}
		\begin{align*}
			Var(aX)&=E((aX-E(aX))^2)\\
			&=E((aX-aE(X))^2)\\
			&=E(a^2(X-E(X))^2)\\
			&=a^2E((X-E(X))^2)\qedhere
		\end{align*}
	\end{proof}
	\item $Var(X+a)=Var(X)$
	\begin{proof}
		\begin{align*}
			Var(X+a)&=E((X+a-E(X+a))^2)\\
			&=E((X+a-E(X)+E(a))^2)\\
			&=E((X+a-E(X)+a)^2)\\
			&=E((X-E(X))^2)\\
			&=Var(X)\qedhere
		\end{align*}
	\end{proof}
\end{enumerate}
\begin{esercizio}
	Abbiamo due urne
	\begin{enumerate}
		\item La prima urna contiene 1 palline dorata, 4 palline verdi e 15 palline bianche
		\item La seconda urna contiene 4 palline verdi e 25 palline bianche
	\end{enumerate}
	Viene spostata una pallina scelta a caso dall'urna 1 all'urna 2, e successivamente estraiamo una pallina dall'urna 2.
	\begin{itemize}
		\item Se estraiamo la pallina dorata, vinciamo 50€
		\item Se estraiamo una pallina verde, perdiamo 1€
	\end{itemize}
	Sia $X$ la variabile aleatoria che rappresenta la vincita, si calcoli la sua varianza.
	\begin{soluzione}
		I valori che può assumere $X$ sono
		\begin{equation*}
			\mathcal{X}=\{-1,0,50\}
		\end{equation*}
		Per comodità di notazione, definiamo i seguenti eventi:
		\begin{align*}
			E_i&=\text{"Estrazione dall'urna 2 una pallina di colore $i$"}\\
			T_i&=\text{"Trasferimento dall'urna 1 all'urna 2 una pallina di colore $i$"}
		\end{align*}
		Ricordando la formula di probabilità totale, la densità discreta di $X$ è:
		\begin{align*}
			p_X(-1)&=P(E_V)\\
			&=P(E_V|T_D)\cdot P(T_D)+P(E_V|T_V)\cdot P(T_V)+P(E_V|T_B)\cdot P(T_B)\\
			&=\frac{4}{30}\cdot\frac{1}{20}+\frac{5}{30}\cdot\frac{4}{20}+\frac{4}{30}\cdot\frac{15}{20}=\frac{7}{50}\\
			p_X(0)&=P(E_B)\\
			&=P(E_B|T_D)\cdot P(T_D)+P(E_B|T_V)\cdot P(T_V)+P(E_B|T_B)\cdot P(T_B)\\
			&=\frac{25}{30}\cdot\frac{1}{20}+\frac{25}{30}\cdot\frac{4}{20}+\frac{26}{30}\cdot\frac{15}{20}=\frac{103}{120}\\
			p_X(50)&=P(E_D)\\
			&=P(E_D|T_D)\cdot P(T_D)+P(E_D|T_V)\cdot P(T_V)+P(E_D|T_B)\cdot P(T_B)\\
			&=\frac{1}{30}\cdot\frac{1}{20}+\frac{0}{30}\cdot\frac{4}{20}+\frac{0}{30}\cdot\frac{15}{20}=\frac{1}{600}
		\end{align*}
		Calcoliamo ora la varianza:
		\begin{align*}
			Var(X)&=E(X^2)-(E(X))^2\\
			&=\left[(-1)^2\cdot\frac{7}{50}+(0)^2\cdot\frac{103}{120}+(50)^2\cdot\frac{1}{600}\right]\\
			&-\left[(-1)\cdot\frac{7}{50}+(0)\cdot\frac{103}{120}+(50)\cdot\frac{1}{600}\right]^2\approx4.3\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
% subsection varianza (end)
\subsection{Variabili Aleatorie Discrete Notevoli} % (fold)
\label{sub:variabili_aleatorie_discrete_notevoli}
\begin{definizione}
	Siano $X$ e $Y$ due varibili aleatorie con lo stesso alfabeto, e con stessa densità di probabilità sugli stessi valori:
	\begin{align*}
		\mathcal{X}&=\mathcal{Y}\\
		p_X(x_k)&=p_Y(y_j)\quad\forall x_k=y_j
	\end{align*}
	Allora $X$ e $Y$ si dicono probabilisticamente equivalenti e si indica
	\begin{equation*}
		X\sim Y
	\end{equation*}
\end{definizione}
\begin{NB}
	È sbagliato dire che $X=Y$, perché le due variabili potrebbero essere definite su spazi di probabilità completamente diversi.
\end{NB}
\subsubsection{Alfabeto Finito} % (fold)
\label{ssub:alfabeto_finito}
\paragraph{Variabili Aleatorie di Bernoulli} % (fold)
\label{par:variabili_aleatorie_di_bernoulli}
Le variabili aleatorie di Bernoulli rappresentano il risultato di una singola prova in uno schema di Bernoulli. Una variabile $X$ è variabile di Bernoulli, e si indica con
\begin{equation*}
	X\sim Be(p)\quad\text{con }p\in[0,1]
\end{equation*}
se è caratterizzata da:
\begin{align*}
	\mathcal{X}&=\{0,1\}\\
	p_X(1)&=p\\
	p_X(0)&=1-p\\
	E(X)&=p\\
	Var(X)&=1-p
\end{align*}
\begin{esempio}
	La variabile $\mathds{1}_E$ è una varibile di Bernoulli:
	\begin{equation*}
		\mathds{1}_E\sim Be(P(E))
	\end{equation*}
\end{esempio}
% paragraph variabili_aleatorie_di_bernoulli (end)
\paragraph{Variabili Aleatorie Binomiali} % (fold)
\label{par:variabili_aleatorie_binomiali}
Una variabile $X$ è variabile binomiale, e si indica con
\begin{equation*}
	X\sim Bin(n,p)\quad\text{con }p\in[0,1],n\in\mathds{N}\smallsetminus\{0\}
\end{equation*}
se è caratterizzata da:
\begin{align*}
	\mathcal{X}&=\{0,1,\dots,n\}\\
	p_X(k)&=\binom{n}{k} p^k (1-p)^{n-k}\quad\forall k\in\mathcal{X}\\
	E(X)&=n p\\
	Var(X)&=n p(1-p)
\end{align*}
Le variabili di questa famiglia sono quelle associate agli schemi di Bernoulli.
\begin{osservazione}
	Se all'$i$-esima prova viene associata una variabile di Bernoulli $X_i\sim Be(p)$, la variabile $X\sim Bin(n,p)$ è la somma delle $X_i$:
	\begin{equation*}
		X=\sum_{i=1}^n X_i\sim Bin(n,p)
	\end{equation*}
	Infatti, siccome $X_i$ vale $1$ se e solo se l'$i$-esima prova ha avuto successo, la somma degli $X_i$ è il numero di prove che hanno avuto successo.
\end{osservazione}
Dimostriamo solo il calcolo del valor medio:
\begin{proof}
	\begin{align*}
		E(X)&=\sum_{k=0}^n k\cdot p_X(k)\\
		&=\sum_{k=0}^n k\cdot\binom{n}{k}\cdot p^k\cdot (1-p)^{n-k}\\
		&=0\cdot\binom{n}{k}\cdot p^k\cdot (1-p)^{n-k}+\sum_{k=1}^n k\cdot\binom{n}{k}\cdot p^k\cdot (1-p)^{n-k}\\
		&=\sum_{k=1}^n k\cdot\frac{n!}{(n-k)!k!}\cdot p^k\cdot (1-p)^{n-k}\\
		&=\sum_{k=1}^n \cdot\frac{n!}{(n-k)!(k-1)!}\cdot p^k\cdot (1-p)^{n-k}\\
		&\text{indico $h=k-1$}\\
		&=\sum_{h=0}^{n-1} \cdot\frac{n!}{(n-1-h)!h!}\cdot p^{h+1}\cdot (1-p)^{n-1-h}\\
		&=n\cdot p\cdot\sum_{h=0}^{n-1} \cdot\frac{(n-1)!}{(n-1-h)!h!}\cdot p^h\cdot (1-p)^{n-1-h}\\
	\end{align*}
	La sommatoria corrisponde alla somma dei valori della densità discreta di una variabile aleatoria $Y\sim Bin(n-1,p)$ sui valori del suo alfabeto $\mathcal{Y}=\{0,\dots,n-1\}$; per definizione di $p_Y$, questa somma è $1$
	\begin{equation*}
		=n\cdot p\cdot\sum_{h=0}^{n-1} p_Y(h)=n\cdot p\qedhere
	\end{equation*}
\end{proof}
\begin{esercizio}
	È più facile ottenere almeno un 6 lanciando 4 volte un dado equilibrato, oppure ottenere un doppio 6 lanciando una coppia di dadi 24 volte?
	\begin{soluzione}
		L'esercizio riguarda due esperimenti, entrambi consistenti di prove ripetute, e quindi li studiamo con lo schema di Bernoulli.
		\begin{itemize}
			\item Lanciamo un dado 4 volte, e vediamo se esce almeno un 6. Ciascun lancio si può modellare con una variabile
			\begin{equation*}
				X_i=
				\begin{cases}
					1&\text{se all'$i$-esimo lancio esce 6}\\
					0&\text{altrimenti}
				\end{cases}
			\end{equation*}
			4 lanci $\Rightarrow$ $i\in\{1,2,3,4\}$. Chiaramente:
			\begin{equation*}
				X_i\sim Be\left(\frac{1}{6}\right)
			\end{equation*}
			Il risultato dell'esperimento si può studiare con una variabile aleatoria:
			\begin{equation*}
				X=\sum_{i=1}^4X_i\sim Bin\left(4,\frac{1}{6}\right)
			\end{equation*}
			$X$ è il numero di volte in cui abbiamo ottenuto 6; calcoliamo:
			\begin{align*}
				P(X\geq 1)&=1-P(X<1)\\
				&=1-P(X=0)\\
				&=1-\binom{4}{0}\left(\frac{1}{6}\right)^0\left(1-\frac{1}{6}\right)^4\\
				&=1-\left(\frac{5}{6}\right)^4\approx0.518
			\end{align*}
			\item Lanciamo due dadi 24 volte, e vediamo se esce almeno una volta un doppio 6. Ciascun lancio si può modellare con una variabile
			\begin{equation*}
				Y_i=
				\begin{cases}
					1&\text{se all'$i$-esimo lancio esce un doppio 6}\\
					0&\text{altrimenti}
				\end{cases}
			\end{equation*}
			24 lanci $\Rightarrow$ $i\in\{1,\dots, 24\}$. Chiaramente:
			\begin{equation*}
				Y_i\sim Be\left(\frac{1}{36}\right)
			\end{equation*}
			Il risultato dell'esperimento si può studiare con una variabile aleatoria:
			\begin{equation*}
				Y=\sum_{i=1}^4Y_i\sim Bin\left(24,\frac{1}{36}\right)
			\end{equation*}
			$Y$ è il numero di volte in cui abbiamo ottenuto un doppio 6; analogamente a prima:
			\begin{align*}
				P(Y\geq 1)&=1-P(Y<1)\\
				&=1-P(Y=0)\\
				&=1-\binom{24}{0}\left(\frac{1}{36}\right)^0\left(1-\frac{1}{36}\right)^{24}\\
				&=1-\left(\frac{35}{36}\right)^{24}\approx0.49
			\end{align*}
		\end{itemize}
		Quindi è più probabile ottenere un 6 con un dado che ottenere una coppia di 6 con due dadi, anche con molti più lanci. Notevole è il fatto che le due variabili $X$ e $Y$ hanno stesso valor medio e stessa varianza, ma ciò non significa che le due variabili si comportano allo stesso modo.
	\end{soluzione}
\end{esercizio}
% paragraph variabili_aleatorie_binomiali (end)
% subsubsection alfabeto_finito (end)
\subsubsection{Alfabeto Infinito} % (fold)
\label{ssub:alfabeto_infinito}
\paragraph{Variabili Aleatorie Geometriche} % (fold)
\label{par:variabili_aleatorie_geometriche}
\begin{NB}
	Indichiamo:
	\begin{align*}
		\mathds{N}&=\{1,2,3,\dots\}\\
		\mathds{N}_0&=\{0,1,2,3,\dots\}
	\end{align*}
\end{NB}
Una variabile $X$ si dice geometrica, e si indica
\begin{equation*}
	X\sim Ge(p)\quad\text{con }p\in[0,1]
\end{equation*}
se è caratterizzata da:
\begin{align*}
	\mathcal{X}&=\mathds{N}\\
	p_X(k)&=(1-p)^{k-1}p\\
	E(X)&=\frac{1}{p}\\
	Var(X)&=\frac{1-p}{p^2}
\end{align*}
Una variabile aleatoria geometrica rappresenta, in uno schema di Bernoulli, l'indice della prima prova che ha successo. Se consideriamo le variabili $X_i\sim Be(p)$, con $p$ probabilità che una prova abbia successo e $i\in\mathds{N}$ allora:
\begin{equation*}
	X=min\{i\in\mathds{N}|X_i=1\}\sim Ge(p)
\end{equation*}
La densità discreta di $X$ segue da questa osservazione: se $X=k$, allora $X_i=0$ $\forall i<k$ e $X_k=1$. Segue:
\begin{align*}
	p_X(k)&=P(X=k)\\
	&=P(X_1=0, X_2=0,\dots, X_{k-1}=0, X_k=1)\\
	&\text{per l'indipendenza e l'equiprobabilità delle prove:}\\
	&=\prod_{j=1}^{k-1} P(X_j=0)P(X_k=1)\\
	&=(1-p)^{k-1}p
\end{align*}
\begin{osservazione}
	La funzione
	\begin{equation*}
		p_X(k)=(1-p)^{k-1}p\quad k\in\mathds{N}
	\end{equation*}
	è una densità discreta di probabilità. Infatti:
	\begin{itemize}
		\item $p_X(k)\geq0$ $\forall k\in\mathds{N}$, trivialmente
		\item $\sum_{k\in\mathds{N}}p_X(k)=1$, perché
		\begin{align*}
			\sum_{k\in\mathds{N}}p_X(k)&=\sum_{k\in\mathds{N}}(1-p)^{k-1}p\\
			&=p\sum_{k\in\mathds{N}}(1-p)^{k-1}\\
			&\text{indicando }h=k-1\\
			&=p\sum_{h\in\mathds{N}_0}(1-p)^h\\
			&\text{per la convergenza della serie geometrica:}\\
			&=p\cdot\frac{1}{1-(1-p)}=1
		\end{align*}
	\end{itemize}
\end{osservazione}
Dimostriamo il calcolo del valor medio:
\begin{align*}
	E(X)&=\sum_{k\in\mathds{N}}k\cdot p_X(k)\\
	&=\sum_{k\in\mathds{N}}k\cdot(1-p)^{k-1}\cdot p\\
	&=p\sum_{k\in\mathds{N}}k\cdot(1-p)^{k-1}\\
	&\text{ricordiamo che:}\\
	&k(1-p)^{k-1}=-\frac{d}{dp}[(1-p)^k]\\
	&\text{segue:}\\
	&=-p\sum_{k\in\mathds{N}}\frac{d}{dp}[(1-p)^k]\\
	&\text{per la linearità della derivata:}\\
	&=-p\frac{d}{dp}\left[\sum_{k\in\mathds{N}}(1-p)^k\right]\\
	&\text{per $k=0$ risulta un termine $1$ della somma,}\\
	&\text{che quindi è irrilevante per la derivata,}\\
	&\text{e quindi si può far partire la sommatoria da $0$}\\
	&=-p\frac{d}{dp}\left[\sum_{k\in\mathds{N}_0}(1-p)^k\right]\\
	&=-p\frac{d}{dp}\left[\frac{1}{p}\right]\\
	&=-p\left(-\frac{1}{p^2}\right)=\frac{1}{p}
\end{align*}
Per il calcolo della varianza si utilizza lo stesso "trucco", ma utilizzando la derivata seconda, perché invece di $k$ c'è $k^2$.
\begin{nota}
	In alcuni libri, la variabile geometrica è definita come il numero di insuccessi prima del primo successo, invece dell'indice del primo successo stesso. Risulta che il valore di questa variabile è traslato di $-1$ rispetto alla variabile geometrica che usiamo noi. Le differenze sono poche: l'alfabeto è $\mathds{N}_0$ e la densità discreta ha $k$ invece di $k-1$ all'esponente; valor medio e varianza si possono ottenere considerando $E(X-1)$ e $Var(X-1)$.
\end{nota}
\begin{esercizio}
	Una probabilità notevole da calcolare relativa alle variabili aleatorie geometriche è detta probabilità di lunga attesa, cioè la probabilità che il primo successo avvenga dopo una certa prova $k$:
	\begin{equation*}
		P(X>k)
	\end{equation*}
	\begin{soluzione}
		\begin{align*}
			P(X>k)&=\sum_{j=k+1}^{+\infty}P(X=j)\\
			&=\sum_{j=k+1}^{+\infty}(1-p)^{j-1}p\\
			&=p\sum_{j=k+1}^{+\infty}(1-p)^{j-1}\\
			&\text{indico }h=j-k-1\\
			&=p\sum_{h=0}^{+\infty}(1-p)^{h+k}\\
			&=p(1-p)^k\sum_{h=0}^{+\infty}(1-p)^h\\
			&=p(1-p)^k\frac{1}{p}=(1-p)^k\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
\begin{esercizio}
	Alla roulette (numeri da 0 a 36) si scommette ripetutamente su un numero tra 1 e 12 (compresi). Si calcoli:
	\begin{enumerate}
		\item La probabilità di perdere nelle prime 5 giocate
		\item La probabilità di vincere alla sesta giocata
	\end{enumerate}
	\begin{soluzione}
		La situazione si può inserire in uno schema di Bernoulli: ciascuna prova corrisponde ad una giocata, e una prova ha successo se in quella giocata esce un numro compreso in senso largo fra 1 e 12. Ciascuna prova ha successo con probabilità $\frac{12}{37}$, e a priori non sappiamo quante prove vengono eseguite. Definiamo una variabile geometrica associata all'esperimento:
		\begin{equation*}
			X\sim Ge\left(\frac{12}{37}\right)
		\end{equation*}
		Possiamo risolvere i due quesiti:
		\begin{enumerate}
			\item La probabilità di perdere nelle prime 5 giocate è data dalla probabilità di lunga attesa:
			\begin{equation*}
				P(X\geq 5)=\left(1-\frac{12}{37}\right)^5\approx0.14
			\end{equation*}
			\item La probabilità di vincere alla sesta giocata è:
			\begin{equation*}
				P(X=6)=p_X(6)=\left(1-\frac{12}{37}\right)^5\cdot\frac{12}{37}\approx0.046\qedhere
			\end{equation*}
		\end{enumerate}
	\end{soluzione}
\end{esercizio}
% paragraph variabili_aleatorie_geometriche (end)
\paragraph{Variabili Aleatorie di Poisson} % (fold)
\label{par:variabili_aleatorie_di_poisson}
Una variabile aleatoria $X$ si dice di Poisson, o con distribuzione come Poisson, e si indica
\begin{equation*}
	X\sim Po(\lambda)
\end{equation*}
se è caratterizzata da
\begin{align*}
	\mathcal{X}&=\mathds{N}_0\\
	p_X(k)&=e^{-\lambda}\frac{\lambda^k}{k!}\\
	E(X)&=\lambda\\
	Var(X)&=\lambda
\end{align*}
$p_X(k)$ è una densità discreta perché lo sviluppo in serie di Taylor di $e^x$ è:
\begin{equation*}
	e^x=\sum_{n=0}^{+\infty}\frac{x^n}{n!}
\end{equation*}
quindi:
\begin{align*}
	\sum_{k=0}^{+\infty}p_X(k)&=\sum_{k=0}^{+\infty}e^{-\lambda}\frac{\lambda^k}{k!}\\
	&=e^{-\lambda}\sum_{k=0}^{+\infty}\frac{\lambda^k}{k!}\\
	&=e^{-\lambda}\cdot e^{\lambda}=1
\end{align*}
Dimostriamo $E(X)$:
\begin{proof}
	\begin{align*}
		E(X)&=\sum_{k\in\mathds{N}_0}k\cdot p_X(k)\\
		&=\sum_{k=0}^{+\infty}k\cdot e^{-\lambda}\frac{\lambda^k}{k!}\\
		&\text{per }k=0\text{ si ottiene un addendo pari a }0\\
		&=e^{-\lambda}\sum_{k=1}^{+\infty}k\cdot\frac{\lambda^k}{k!}\\
		&k\neq0\Rightarrow\text{si semplifica:}\\
		&=e^{-\lambda}\sum_{k=1}^{+\infty}\frac{\lambda^k}{(k-1)!}\\
		&\text{indico }h=k-1\\
		&=e^{-\lambda}\sum_{h=0}^{+\infty}\frac{\lambda^{h+1}}{h!}\\
		&=e^{-\lambda}\lambda\sum_{h=0}^{+\infty}\frac{\lambda^h}{h!}\\
		&=e^{-\lambda}\lambda e^{\lambda}=\lambda\qedhere
	\end{align*}
\end{proof}
Per la varianza il ragionamento è molto simile. Le variabili di Poisson si usano per studiare eventi che si verificano molto poco probabilmente, ma per cui vengono eseguite molte prove. Si possono vedere come un limite per $n\to+\infty$ di $Bin(n,p)$; in particolare, il valore di una variabile aleatoria $Po(\lambda)$ è, come per $Bin(n,p)$, il numero di volte in cui una prova ha successo in uno schema di Bernoulli, in cui vengano eseguite molte prove, con una $p$ molto piccola. Formalizzeremo questo concetto.
\begin{esercizio}
	Il numero di meteoriti che colpiscono un satellite durante la sua orbita si distribuisce come una variabile aleatoria di Poisson di parametro $\lambda$. Il satellite compie un'orbita in un giorno, ed in media è colpito da 3 meteoriti. Si calcoli la probabilità che nel percorrere 5 orbite il numero di meteoriti che colpiscono il satellite sia $\leq3$.
	\begin{soluzione}
		Dal testo, il numero di meteoriti che colpiscono un satellite durante la sua orbita è $X\sim Po(\lambda)$. Siccome la domanda si riferisce a 5 orbite, studieremo questo caso specifico. In media il satellite viene colpito da 3 meteoriti per orbita, quindi in media in 5 orbite verrà colpito da 15 meteoriti. Quindi:
		\begin{equation*}
			E(X)=15\wedge E(X)=\lambda\Rightarrow \lambda=15
		\end{equation*}
		Segue:
		\begin{equation*}
			p_X(k)=e^{-15}\frac{15^k}{k!}
		\end{equation*}
		Calcoliamo:
		\begin{align*}
			P(X\leq3)&=p_X(0)+p_X(1)+p_X(2)+p_X(3)\\
			&=e^{-15}\frac{15^0}{0!}+e^{-15}\frac{15^1}{1!}+e^{-15}\frac{15^2}{2!}+e^{-15}\frac{15^3}{3!}\approx 0.0002\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
Formaliziamo l'intuizione che $Po(\lambda)$ sia il limite di $Bin(n,p)$ per n grandi attraverso un teorema:
\begin{teorema}[Limite di Poisson]
	Siano $X_n$ e $Y$ due variabili aleatorie tali che
	\begin{align*}
		X_n&\sim Bin\left(n, \frac{\lambda}{n}\right)\\
		Y&\sim Po(\lambda)
	\end{align*}
	Allora
	\begin{equation*}
		\forall k\in\mathds{N}_0\quad \lim_{n\to+\infty}p_{X_n}(k)=p_Y(k)
	\end{equation*}
\end{teorema}
\begin{proof}
	Dalle caratteristiche di $X_n$ vale:
	\begin{align*}
		p_X_n(k)&=\binom{n}{k}\left(\frac{\lambda}{n}\right)^k\left(1-\frac{\lambda}{n}\right)^{n-k}\\
		&=\frac{n!}{(n-k)!k!}\frac{\lambda^k}{n^k}\left(1-\frac{\lambda}{n}\right)^{n-k}\\
		&=\frac{n\cdot(n-1)\cdot\dots\cdot(n-k+1)}{n^k}\cdot\frac{\lambda^k}{k!}\cdot\frac{\left(1-\frac{\lambda}{n}\right)^n}{\left(1-\frac{\lambda}{n}\right)^k}\\
	\end{align*}
	Portando al limite:
	\begin{equation*}
		\lim_{n\to+\infty}\frac{n\cdot(n-1)\cdot\dots\cdot(n-k+1)}{n^k}\cdot\frac{\lambda^k}{k!}\cdot\frac{\left(1-\frac{\lambda}{n}\right)^n}{\left(1-\frac{\lambda}{n}\right)^k}
	\end{equation*}
	Per le proprietà dei limiti:
	\begin{align*}
		&\lim_{n\to+\infty}\frac{n\cdot(n-1)\cdot\dots\cdot(n-k+1)}{n^k}=\lim_{n\to+\infty}\frac{n^k+o(n^k)}{n^k}=1\\
		&\lim_{n\to+\infty}\frac{\lambda^k}{k!}=\frac{\lambda^k}{k!}\\
		&\lim_{n\to+\infty}\left(1-\frac{\lambda}{n}\right)^n=e^{-\lambda}\\
		&\lim_{n\to+\infty}\left(1-\frac{\lambda}{n}\right)^k=1
	\end{align*}
	Segue:
	\begin{align*}
		\lim_{n\to+\infty}p_{X_n}(k)&=\lim_{n\to+\infty}\frac{n\cdot(n-1)\cdot\dots\cdot(n-k+1)}{n^k}\cdot\frac{\lambda^k}{k!}\cdot\frac{\left(1-\frac{\lambda}{n}\right)^n}{\left(1-\frac{\lambda}{n}\right)^k}\\
		&=1\cdot\frac{\lambda^k}{k!}\cdot \frac{e^{-\lambda}}{1}\\
		&=e^{-\lambda}\frac{\lambda^k}{k!}=p_Y(k)\qedhere
	\end{align*}
\end{proof}
Euristicamente si verifica che $Bin(n,p)$ si può approssimare con $Po(np)$ se
\begin{align*}
	n&>100\\
	p&<0.01\\
	np&\leq20
\end{align*}
Si può dimostrare che dal Teorema Limite di Poisson seguono anche
\begin{align*}
	\lim_{n\to+\infty}E(X_n)&=E(Y)\\
	\lim_{n\to+\infty}Var(X_n)&=Var(Y)\\
\end{align*}
Nelle applicazioni reali il teorema si può applicare a situazioni compatibili con lo schema di Bernoulli in cui si verificano un numero $n\gg1$ di prove ripetute indipendenti, ciascuna con una probabilità $p\ll1$ di avere successo. Generalmente $n$ e $p$ non sono noti (ad esempio, il numero di terremoti di intensità più alta di una certa soglia in una zona sismica non è misurabile, non si possono contare uno per uno, e soprattutto non si può calcolare con una certa accuratezza la probabilità che se ne verifichi uno), ma si può calcolare la media (eseguendo misurazioni ripetute nel tempo), che per le variabili di famiglia $Bin(n,p)$ è $np$. Non essendo noti $n$ e $p$ non si può usare una variabile binomiale, e quindi si approssima con una variabile di Poisson $Po(\lambda)=Po(np)$. Oltretutto, per $n$ grandi il calcolo dei coefficienti binomiali nella densità discreta di $Bin(n,p)$ diventa molto difficoltoso, mentre la densità discreta di $Po(\lambda)$ è sempre molto calcolabile. Negli esercizi, le possibilità di applicazione del Teorema Limite sono due:
\begin{itemize}
	\item Può essere che siano dati un numero di prove e una probabilità di successo che rispettano l'euristica, e per cui i calcoli con $B(n,p)$ sono difficili
	\item Può essere che non siano dati $n$ e $p$ ma direttamente il valore medio $np$, e quindi si usa direttamente $Po(np)$
\end{itemize}
\begin{esercizio}
	La probabilità che in una partita di poker venga servito un full è $0.0014$. Vengono giocate 1000 partite. Calcolare la probabilità che vengano serviti alpiù 3 full.
	\begin{soluzione}
		L'esercizio si può studiare attraverso uno schema di Bernoulli in cui:
		\begin{itemize}
			\item La prova ripetuta è una partita di poker, e il successo consiste nel servizio di un full.
			\item Il numero di prove ripetute è $n=1000$
			\item la probabilità di successo è $p=0.0014$
		\end{itemize}
		Il numero di successi su $n$ prove si può rappresentare con una variabile aleatoria $X$ tale che:
		\begin{equation*}
			X\sim Bin(n,p)=Bin(1000,0.0014)
		\end{equation*}
		Valgono
		\begin{align*}
			n&=1000>100\\
			p&=0.0014<0.01\\
			np&=1.4\leq20
		\end{align*}
		Possiamo quindi utilizzare l'approssimazione di Poisson: consideriamo una variabile aleatoria $Y$ tale che:
		\begin{equation*}
			Y\sim Po(np)=Po(1.4)
		\end{equation*}
		Calcoliamo la probabilità richiesta:
		\begin{align*}
			&P(X\leq3)\approx\\
			& P(Y\leq3)=\\
			&P(Y=0)+P(Y=1)+P(Y=2)+P(Y=3)=\\
			&e^{-1.4}\frac{(1.4)^0}{0!}+e^{-1.4}\frac{(1.4)^1}{1!}+e^{-1.4}\frac{(1.4)^2}{2!}+e^{-1.4}\frac{(1.4)^3}{3!}\approx0.95\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
\begin{esercizio}
	Il numero di influenze che una data persona contrae in un anno si distribuisce come $Po(5)$. Viene proposto un vaccino che fa diminuire a $3$ il numero di influenze contratte annualmente, ma funziona solo nel $75\%$ dei casi. Se un individuo si vaccina e quell'anno contrae solo 2 influenze, qual è la probabilità che il vaccino sia stato efficace?
	\begin{soluzione}
		Definiamo alcuni eventi di interesse:
		\begin{align*}
			E&=\{\text{"il vaccino è stato efficace"}\}\\
			F&=\{\text{"l'individuo è vaccinato e contrae 2 influenze"}\}\\
		\end{align*}
		Definiamo inoltre le variabili aleatorie
		\begin{equation*}
			X_i=Po(i)\quad i\in\{3,5\}
		\end{equation*}
		Dobbiamo calcolare la probabilità $P(E|F)$. Non abbiamo informazioni su questa probabilità condizionata, ma possiamo ricavarne sul contrario, quindi applichiamo il Teorema di Bayes e la formula di probabilità totale:
		\begin{align*}
			P(E|F)&=\frac{P(F|E)P(E)}{P(F)}\\
			&=\frac{P(F|E)P(E)}{P(F|E)P(E)+P(F|E^C)P(E^C)}\\
		\end{align*}
		Dal testo, $P(E)=0.75$, e quindi $P(E^C)=0.25$. Le probabilità condizionate a $E$ e $E^C$ sono date dalle probabilità che le rispettive variabili aleatorie di Poisson valgano 2:
		\begin{align*}
			&\frac{P(F|E)P(E)}{P(F|E)P(E)+P(F|E^C)P(E^C)}=\\
			&\frac{P(X_3=2)P(E)}{P(X_3=2)P(E)+P(X_5=2)P(E^C)}=\\
			&\frac{e^{-3}\frac{3^2}{2!}\cdot0.75}{e^{-3}\frac{3^2}{2!}\cdot0.75+e^{-5}\frac{5^2}{2!}\cdot0.25}
		\end{align*}
	\end{soluzione}
\end{esercizio}
% paragraph variabili_aleatorie_di_poisson (end)
% subsubsection alfabeto_infinito (end)
% subsection variabili_aleatorie_discrete_notevoli (end)
% section variabili_aleatorie_discrete (end)
\section{Vettori Aleatori Discreti} % (fold)
\label{sec:vettori_aleatori_discreti}
Con gli strumenti che abbiamo non siamo ancora in grado di calcolare alcune cose che idealmente dovrebbero essere semplici, ad esempio $E(XY)$ oppure $Var(X+Y)$, con $X$ e $Y$ variabili aleatorie. Consideriamo in particolare $Var(X+Y)$:
\begin{align*}
	Var(X+Y)&=E[(X+Y-E(X+Y))^2]\\
	&=E[(X-E(X)+Y-E(Y))^2]\\
	&=E[(X-E(X))^2+(Y-E(Y))^2+2(X-E(X))(Y-E(Y))]\\
	&=E[(X-E(X))^2]+E[(Y-E(Y))^2]+2E[(X-E(X))(Y-E(Y))]
\end{align*}
Definiamo una grandezza che caratterizza $X$ e $Y$:
\begin{definizione}
	Si definisce la covarianza fra due variabili aleatorie $X$ e $Y$:
	\begin{equation*}
		Cov(X,Y)=E[(X-E(X))(Y-E(Y))]
	\end{equation*}
\end{definizione}
Risulta:
\begin{equation*}
	Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)
\end{equation*}
Dobbiamo analizzare la covarianza più nel dettaglio. Osserviamo, dalla definizione, due cose:
\begin{osservazione}
	\begin{equation*}
		Y=X \Rightarrow Cov(X,Y)=Cov(X,X)=Var(X)
	\end{equation*}
\end{osservazione}
\begin{osservazione}
	\begin{align*}
		Cov(X,Y)&=E[(X-E(X))(Y-E(Y))]\\
		&=E[XY-YE(X)-XE(Y)+E(X)E(Y))]\\
		&=E(XY)-E(X)E(Y)\cancel{-E(X)E(Y)}\cancel{+E(X)E(Y)}\\
		&=E(XY)-E(X)E(Y)
	\end{align*}
	Questa è una definizione alternativa della covarianza.
\end{osservazione}
Per calcolare la covarianza sfruttando l'Osservazione 2, avendo caratterizzato $X$ e $Y$ attraverso i rispettivi alfabeti e le rispettive densità discrete, è piuttosto semplice calcolare $E(X)$ e $E(Y)$; per calcolare $E(XY)$ è necessario caratterizzare la variabile $XY$, e in particolare calcolare $p_{XY}(x_i\cdot y_j)$ per ogni coppia $(x_i,y_j)\in\mathcal{X}\times\mathcal{Y}$. Questi valori della densità discreta corrispondono alle probabilità $P(X=x_i,Y=y_j)$, che corrispondono alle probabilità delle intersezioni fra i due eventi $\{X=x_i\}$ e $\{Y=y_j\}$; queste probabilità sono calcolabili esplicitamente solo se i due eventi sono indipendenti. Il motivo per cui non sono calcolabili in generale a partire da $p_X$ e $p_Y$ è che racchiudono e codificano tutte le informazioni sul modo in cui $X$ e $Y$ si relazionano, che sono assenti dalle densità discrete prese singolarmente. Dobbiamo quindi definire un costrutto più potente delle variabili aleatorie per trattare questi casi:
\begin{definizione}
	Sia $(\Omega, \mathds{P}(\Omega), P)$ uno spazio di probabilità discreto. Si dice vettore aleatorio $n$-dimensionale una funzione:
	\begin{align*}
		\bm{V}:\Omega&\to\Mathds{R}^n\\
		\omega&\mapsto\bm{V}(\omega)=(X_1 (\omega),\dots,X_n (\omega))
	\end{align*}
\end{definizione}
Noi ci concentreremo sul caso $n=2$:
\begin{align*}
	\bm{V}:\Omega&\to\Mathds{R}^2\\
		\omega&\mapsto\bm{V}(\omega)=(X(\omega),Y(\omega))
\end{align*}
$X$ e $Y$ sono variabili aleatorie discrete, come quelle che abbiamo visto fino adesso, con alfabeti $\mathcal{X}$ e $\mathcal{Y}$ e densità discrete $p_X$ e $p_Y$.
\subsection{Caratterizzazione dei Vettori Aleatori} % (fold)
\label{sub:caratterizzazione_dei_vettori_aleatori}
Cerchiamo adesso di caratterizzare i vettori aleatori come abbiamo fatto per le variabili aleatorie.
\begin{definizione}
	Sia $\bm{V}$ un vettore aleatorio discreto bidimensionale. Si dice alfabeto di $\bm{V}$ l'insieme delle coppie di valori che il vettore può assumere. Si ha
	\begin{equation*}
		\mathcal{V}\subseteq\mathcal{X}\times\mathcal{Y}
	\end{equation*}
\end{definizione}
Generalemente l'inclusione $\mathcal{V}\subseteq\mathcal{X}\times\mathcal{Y}$ è un'inclusione stretta. Si verifica l'uguaglianza quando $\{X=x_i\}$ e $\{Y=y_j\}$ sono eventi indipendenti per ogni coppia $(x_i,y_j)\in\mathcal{X}\times\mathcal{Y}$. Definiamo andesso il corrispettivo della densità discreta:
\begin{definizione}
	Si chiama densità discreta congiunta di un vettore aleatorio $\bm{V}=(X,Y)$, o più comunemente delle variabili $X$ e $Y$, la mappa
	\begin{align*}
		p_{XY}:\mathcal{X}\times\mathcal{Y}&\to[0,1]\\
		(x_i,y_j)&\mapsto P(X=x_i,Y=y_j)
	\end{align*}
\end{definizione}
\begin{osservazione}
	Si considera $\mathcal{X}\times\mathcal{Y}$ come dominio di $p_{XY}$ per comodità. Per i punti $(x_i,y_j)\notin\mathcal{V}$ vale $p_{XY}(x_i,y_j)=0$, perché se $\bm{V}$ non può assumere valore $(x_i,y_j)$, significa che $\{X=x_i\}\cap\{Y=y_j\}=\emptyset$
\end{osservazione}
La densità congiunta è una misura di probabilità, quindi vale
\begin{enumerate}
	\item
	\begin{equation*}
		p_{XY}(x_i , y_j)\geq0\quad\forall(x_i , y_j)\in\mathcal{V}
	\end{equation*}
	\item 
	\begin{equation*}
		\sum_{x_i\in\mathcal{X}}\sum_{y_j\in\mathcal{Y}}p_{XY}(x_i,y_j)=1
	\end{equation*}
\end{enumerate}
\begin{lemma}
	Le densità discrete $p_X$ e $p_Y$ di $X$ e $Y$ rispettivamente (dette anche densità marginali) si ottengono da $p_{XY}$ come
	\begin{align*}
		p_X(x_i)=\sum_{y_j\in\mathcal{Y}}p_{XY}(y_j)&& p_Y(y_j)=\sum_{x_i\in\mathcal{X}}p_{XY}(x_i)
	\end{align*}
\end{lemma}
Mentre è possibile calcolare le densità marginali dalla densità congiunta, non è sempre possibile il viceversa. Si possono adesso definire valor medio e varianza di variabili aleatorie ottenute come funzioni di più variabili aleatorie (cioè come funzioni di vettori aleatori):
\begin{definizione}
	Sia $(X,Y)$ vettore aleatorio discreto, sia $g:\mathds{R}^2\to\mathds{R}$ funzione sufficientemente regolare. Allora si definisce
	\begin{equation*}
		E[g(X,Y)]=\sum_{x_i\in\mathcal{X}}\sum_{y_j\in\mathcal{Y}}g(x_i,y_j)p_{XY}(x_i,y_j)
	\end{equation*}
\end{definizione}
% subsection caratterizzazione_dei_vettori_aleatori (end)
\subsection{Indipendenza fra Variabili Aleatorie} % (fold)
\label{sub:indipendenza_fra_variabili_aleatorie}
Introduciamo il concetto di indipendenza fra variabili aleatorie per una coppia di variabili:
\begin{definizione}
	La coppia $(X,Y)$ si dice indipendente (o analogamente $X$ e $Y$ si dicono indipendenti) se e solo se 
	\begin{equation*}
		p_{XY}(x_i,y_j)=p_X(x_i)p_Y(y_j)\quad\forall x_i\in\mathcal{X},\forall y_j\in\mathcal{Y}
	\end{equation*}
\end{definizione}
La definizione è analoga a quella di eventi indipendenti, con la differenza che in questo caso bisogna dimostrare che tutte le probabilità congiunte si fattorizzano nel prodotto delle marginali, quindi generalmente è un calcolo piuttosto oneroso.
\begin{osservazione}
	\begin{equation*}
		X,Y\text{ indipendenti}\Leftrightarrow f(X),g(Y)\text{ indipendenti}\quad\forall f,g:\mathds{R}\to\mathds{R}
	\end{equation*}
\end{osservazione}
Vediamo come questo concetto influenza il valor medio
\begin{teorema}
	Se $X$ e $Y$ sono indipendenti, allora
	\begin{equation*}
		E(XY)=E(X)E(Y)
	\end{equation*}
\end{teorema}
\begin{proof}
	\begin{align*}
		E(XY)&=\sum_{x_i\in\mathcal{X}}\sum_{y_j\in\mathcal{Y}}x_iy_jp_{XY}(x_i,y_j)\\
		&\text{per l'indipendenza di }X\text{ e }Y\text{:}\\
		&=\sum_{x_i\in\mathcal{X}}\sum_{y_j\in\mathcal{Y}}x_iy_jp_X(x_i)p_Y(y_j)\\
		&=\sum_{x_i\in\mathcal{X}}x_ip_X(x_i)\sum_{y_j\in\mathcal{Y}}y_jp_Y(y_j)\\
		&=E(X)E(Y)\qedhere
	\end{align*}
\end{proof}
Da questo teorema seguono due conseguenze: se $X$ e $Y$ sono indipendenti
\begin{enumerate}
	\item $Cov(X,Y)=0$
	\begin{proof}
		\begin{align*}
			Cov(X,Y)&=E(XY)-E(X)E(Y)\\
			&=E(X)E(Y)-E(X)E(Y)=0\qedhere
		\end{align*}
	\end{proof}
	\begin{nota}
		Se $Cov(X,Y)=0$ allora $X$ e $Y$ si dicono scorrelate. Chiaramente, l'indipendenza implica la scorrelazione; non è vero il viceversa.
	\end{nota}
	\item $Var(X+Y)=Var(X)+Var(Y)$
	\begin{proof}
		Abbiamo visto che
		\begin{equation*}
			Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)
		\end{equation*}
		Ma dal punto 1. $Cov(X,Y)=0$, quindi:
		\begin{equation*}
			Var(X+Y)=Var(X)+Var(Y)\cancel{+2Cov(X,Y)}=Var(X)+Var(Y)\qedhere
		\end{equation*}
	\end{proof}
\end{enumerate}
\begin{NB}
	Dal punto 2. sappiamo che se le variabili sono indipendenti la varianza è additiva, ma non lineare, perché mentre si distribuisce sulle somme, le costanti continuano ad essere "portate fuori" al quadrato.
\end{NB}
\subsubsection{Generalizzazione a più Variabili} % (fold)
\label{ssub:generalizzazione_a_più_variabili}
\begin{definizione}
	L'insieme di variabili aleatorie $\{X_1,X_2,\dots,X_n\}$ è detto indipendente se e solo se
	\begin{equation*}
		p_{X_1,\dots,X_n}(x_1,\dots,x_n)=p_{X_1}(x_1)\cdot\ldots\cdot p_{X_n}(x_n)\quad\forall x_1,\dots,x_n
	\end{equation*}
\end{definizione}
Non vedremo molto sull'indipendenza di più variabili, ma una proprietà importante è
\begin{proposizione}
	Se $X_1,\ldots,X_n$ sono indipendenti, allora
	\begin{equation*}
		Var\left(\sum_{i=1}^nX_i\right)=\sum_{i=1}^nVar(X_i)
	\end{equation*}
\end{proposizione}
% subsubsection generalizzazione_a_più_variabili (end)
\begin{esercizio}
	Si lancia un dado truccato in modo che
	\begin{equation*}
		P(\text{"ottenere punteggio }i\text{"})=
		\begin{cases}
			p&\text{se }i\text{ è dispari}\\
			2p&\text{se }i\text{ è pari}
		\end{cases}
	\end{equation*}
	con $p\in[0,1]$. Indicando con $D$ il punteggio del dado, definiamo le variabili aleatorie
	\begin{equation*}
		X=
		\begin{cases}
			1&\text{se }D\text{ è pari}\\
			0&\text{altrimenti}
		\end{cases}
	\end{equation*}
	e 
	\begin{equation*}
		Y=
		\begin{cases}
			1&\text{se }D>3\\
			0&\text{altrimenti}
		\end{cases}
	\end{equation*}
	Determinare la densità congiunta di $X$ e $Y$.
	\begin{soluzione}
		Determiniamo $p$ sfruttando la condizione di normalizzazione:
		\begin{equation*}
			3p+3(2p)=1\Leftrightarrow p=\frac{1}{9}
		\end{equation*}
		Per il punteggio del dado si ottiene:
		\begin{align*}
			P(D=1)=P(D=3)=P(D=5)&=\frac{1}{9}\\
			P(D=2)=P(D=4)=P(D=6)&=\frac{2}{9}\\
		\end{align*}
		Caratterizziamo il vettore $(X,Y)$: l'alfabeto è
		\begin{equation*}
			\mathcal{X}\times\mathcal{Y}=\{(0,0),(0,1),(1,0),(1,1)\}
		\end{equation*}
		La densità congiunta è data da:
		\begin{align*}
			p_{XY}(0,0)&=P(\{D\text{ dispari}\}\cap \{D\leq3\})\\
			&=P(D\in\{1,3\})\\
			&=P(D=1)+P(D=3)=\frac{2}{9}\\
			p_{XY}(0,1)&=P(\{D\text{ dispari}\}\cap \{D>3\})\\
			&=P(D=5)=\frac{1}{9}\\
			p_{XY}(1,0)&=P(\{D\text{ pari}\}\cap \{D\geq3\})\\
			&=P(D=2)=\frac{2}{9}\\
			p_{XY}(1,1)&=P(\{D\text{ pari}\}\cap \{D>3\})\\
			&=P(D\in\{4,6\})\\
			&=P(D=4)+P(D=6)=\frac{4}{9}\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
\begin{esercizio}
	Sul tavolo ci sono due monete, delle quali una sola è equilibrata. Quella truccata ha una probabilità di ottenere testa di $\frac{1}{3}$. Si sceglie a caso una delle due monete e si lancia due volte. Consideriamo le variabili aleatorie
	\begin{equation*}
		X_i=
		\begin{cases}
			1&\text{se all'}i\text{-esimo lancio si ottiene testa}\\
			0&\text{altrimenti}
		\end{cases}
	\end{equation*}
	per $i=1,2$.
	\begin{enumerate}
		\item Calcolare la densità congiunta di $(X_1,X_2)$
		\item Calcolare $E(X_1)$ e $E(X_2)$
		\item Dire se $X_1$ e $X_2$ sono indipendenti
	\end{enumerate}
	\begin{soluzione}
		\begin{enumerate}
			\item Definiamo l'evento
			\begin{equation*}
				F=\text{"prendiamo la moneta onesta"}
			\end{equation*}
			Possiamo adesso calcolare la densità congiunta di $(X_1,X_2)$, considerando che l'alfabeto di $(X_1,X_2)$ è $\{0,1\}^2$, ed utilizzando la formula di probabilità totale:
			\begin{align*}
				p_{X_1X_2}(0,0)&=P(X_1=0\cap X_2=0)\\
				&=P(X_1=0\cap X_2=0|F)P(F)+P(X_1=0\cap X_2=0|F^C)P(F^C)\\
				&=\frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2}+\frac{2}{3}\cdot\frac{2}{3}\cdot\frac{1}{2}=\frac{25}{72}\\
				p_{X_1X_2}(0,1)&=P(X_1=0\cap X_2=1)\\
				&=P(X_1=0\cap X_2=1|F)P(F)+P(X_1=0\cap X_2=1|F^C)P(F^C)\\
				&=\frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2}+\frac{2}{3}\cdot\frac{1}{3}\cdot\frac{1}{2}=\frac{17}{72}\\
				p_{X_1X_2}(1,0)&=P(X_1=1\cap X_2=0)\\
				&=P(X_1=1\cap X_2=0|F)P(F)+P(X_1=1\cap X_2=0|F^C)P(F^C)\\
				&=\frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2}+\frac{1}{3}\cdot\frac{2}{3}\cdot\frac{1}{2}=\frac{17}{72}\\
				p_{X_1X_2}(1,1)&=P(X_1=1\cap X_2=1)\\
				&=P(X_1=1\cap X_2=1|F)P(F)+P(X_1=1\cap X_2=1|F^C)P(F^C)\\
				&=\frac{1}{2}\cdot\frac{1}{2}\cdot\frac{1}{2}+\frac{1}{3}\cdot\frac{1}{3}\cdot\frac{1}{2}=\frac{13}{72}
			\end{align*}
			\item Notiamo che
			\begin{equation*}
				X_i\sim Be(p_i)
			\end{equation*}
			Quindi, $E(X_i)=p_i$. È quindi sufficiente calcolare le due densità marginali:
			\begin{align*}
				E(X_1)&=p_{X_1}(1)\\
				&=p_{X_1X_2}(1,0)+p_{X_1X_2}(1,1)\\
				&=\frac{17}{72}+\frac{13}{72}=\frac{5}{12}\\
				E(X_2)&=p_{X_2}(1)\\
				&=p_{X_1X_2}(0,1)+p_{X_1X_2}(1,1)\\
				&=\frac{17}{72}+\frac{13}{72}=\frac{5}{12}
			\end{align*}
			\item Non sono indipendenti, perché si ha
			\begin{equation*}
				p_{X_1X_2}(1,1)\neq p_{X_1}(1)p_{X_2}(1)\qedhere
			\end{equation*}
		\end{enumerate}
	\end{soluzione}
\end{esercizio}
% subsection indipendenza_fra_variabili_aleatorie (end)
% section vettori_aleatori_discreti (end)
\section{Variabili Aleatorie Assolutamente Continue} % (fold)
\label{sec:variabili_aleatorie_assolutamente_continue}
La definizione essenzialmente è la stessa delle variabili aleatorie discrete, se non che lo spazio campionario sottostante sarà continuo invece che discreto. In realtà c'è un problema nella definizione della misura di probabilità per spazi campionari di questo tipo, che ha svariate sfaccettature, e che noi non vedremo. Noi daremo una descrizione probabilistica delle variabili aleatorie assolutamente continue, lasciando che lo spazio di probabilità rimanga implicito.
\begin{definizione}
	Una variabile aleatoria $X$ si dice (assolutamente) continua se esiste una funzione $f_X:\mathds{R}\to\mathds{R}$, detta densità di probabilità, tale che per ogni intervallo $[a,b]\subseteq\mathds{R}$ vale
	\begin{equation*}
		P(a\leq X\leq b)=\int_a^bf_X(x)dx
	\end{equation*}
\end{definizione}
\begin{nota}
	\begin{enumerate}
		\item Se non ci sono ambiguità, generalmente la $X$ a pedice di $f$ si omette.
		\item Esistono anche variabili aleatorie continue non assolutamente, ma noi non le vedremo, quindi spesso ometteremo il termine "assolutamente".
	\end{enumerate}
\end{nota}
La funzione $f$ deve soddisfare
\begin{enumerate}
	\item Positività
	\begin{equation*}
		f_X(x)\geq0\quad\forall x\in\mathds{R}
	\end{equation*}
	\item Normalizzazione
	\begin{equation*}
		\int_\mathds{R}f(x)dx=1
	\end{equation*}
\end{enumerate}
\begin{nota}
	La funzione densità di probabilità ha un significato diverso dalla densità discreta, perché quest'ultima è effettivamente una probabilità, invece la funzione $f$ non lo è, mentre lo è il suo integrale.
\end{nota}
\begin{osservazione}
	\begin{itemize}
		\item La funzione $f$ non è necessariamente continua.
		\item La probabilità che $X$ appartenga all'intervallo $[a,b]$ è data dall'area sottesa dal grafico di $f_X$, l'asse $x$ e le due rette $x=a$ e $x=b$.
		\item Non si può parlare di "probabilità che $X$ assuma valore $a$", perché la questa sarebbe data da
		\begin{align*}
			P(X=a)&=\lim_{\varepsilon\to0}P(a-\varepsilon\leq X\leq a+\varepsilon)\\
			&=\lim_{\varepsilon\to0}\int_{a-\varepsilon}^{a+\varepsilon}f_X(x)dx=0
		\end{align*}
		Questo non va interpretato come "l'evento $X=a$ è impossibile", ma il significato è che la probabilità $P(X=a)$ non ha significato nell'ambito delle variabili aleatorie continue.
		\item La funzione $f_x$ va intesa come una densità in senso fisico: per un certo valore $a\in\mathds{R}$, $f_x(a)$ rappresenta non la probabilità di $a$ ma il modo in cui la massa di probabilità di $X$ si distribuisce attorno ad $a$. In un senso molto approssimato, si può intendere $f_X(a)$ come la probabilità che $X$ assuma un valore in un intorno di $a$ diviso l'ampiezza dell'intorno, quando questa ampiezza tende a $0$.
	\end{itemize}
\end{osservazione}
\begin{esercizio}
	Sia $X$ variabile aleatoria continua con densità
	\begin{equation*}
		f_X(x)=
		\begin{cases}
			c(4x-2x^2)&\text{se }0<x<2\\
			0&\text{altrimenti}
		\end{cases}
	\end{equation*}
	Calcoliamo $c$ e $P(X>1)$.
	\begin{soluzione}
		Siccome $f_X$ è una densità deve valere:
		\begin{align*}
			\int_\mathds{R}f(x)dx&=1\\
			\int_{-\infty}^00+\int_0^2c(4x-2x^2)dx+\int_2^{+\infty}&=1\\
			0+c\left[2x^2-\frac{2}{3}x^3\right]_0^2+0&=1\\
			\frac{8}{3}c&=1\\
			c&=\frac{3}{8}
		\end{align*}
		Possiamo calcolare $P(X>1)$:
		\begin{align*}
			P(X>1)&=\int_1^{+\infty}f_X(x)dx\\
			&=\frac{3}{8}\int_1^2(4x-2x^2)=\frac{1}{2}\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
In alcuni casi le stesse informazioni fornite dalla funzione di densità vengono date da un'altra funzione, detta di distribuzione o ripartizione, che può essere più comoda. In questo modo si ottiene una caratterizzazione equivalente della variabile aleatoria in esame.
\begin{definizione}
	Sia $X$ una variabile aleatoria continua. Si dice funzione di distribuzione o di ripartizione di $X$ la funzione
	\begin{align*}
		F_X:\mathds{R}&\to[0,1]\\
		x&\mapsto F_X(x)=P(X\leq x)
	\end{align*}
\end{definizione}
\begin{osservazione}
	Se $F_X$ è nota, possiamo calcolare $P(X\in(a,b])$; infatti:
	\begin{align*}
		P(X\in(a,b])&=P(a<X\leq b)\\
		&=P(\{X\leq b\}\smallsetminus\{X\leq a\})\\
		&=P(\{X\leq b\})-P(\{X\leq a\})\\
		&=F_X(b)-F_X(a)
	\end{align*}
\end{osservazione}
Vediamo due proprietà della funzione di distribuzione
\begin{enumerate}
	\item 
	\begin{align*}
		\lim_{x\to-\infty}F_X(x)=0&&\lim_{x\to+\infty}F_X(x)=1
	\end{align*}
	\item
	\begin{equation*}
		x\leq y\Rightarrow F_X(x)\leq F_X(y)
	\end{equation*}
\end{enumerate}
Fra funzione densità di probabilità e funzione di ripartizione c'è un legame piuttosto stretto, che deriva direttamente dalla definizione di $F_X$:
\begin{align*}
	F_X(x)&=\int_{-\infty}^xf_X(t)dt\\
	f_X(x)&=\frac{d}{dx}F_X(x)
\end{align*}
La funzione di distribuzione si può utilizzare per calcolare la densità di funzioni invertibili di variabili aleatorie; questo non lo formalizziamo, ma lo vediamo con un esempio.
\begin{esempio}
	Supponiamo che $X$ sia una variabile continua con densità $f_X$ e funzione di distribuzione $F_X$. Definiamo $Y=2X$, e determiniamo la densità di $Y$.
	\begin{soluzione}
		La cosa più semplice è caratterizzare la funzione di distribuzione di $Y$:
		\begin{align*}
			F_Y(y)&=P(Y\leq y)\\
			&=P(2X\leq y)\\
			&=P\left(X\leq \frac{y}{2}\right)=F_X\left(\frac{y}{2}\right)
		\end{align*}
		Possiamo quindi calcolare la densità:
		\begin{align*}
			f_Y(y)&=\frac{d}{dy}F_Y(y)\\
			&=\frac{d}{dy}F_X\left(\frac{y}{2}\right)\\
			&=F_X'\left(\frac{y}{2}\right)\cdot\frac{1}{2}=\frac{f_X\left(\frac{y}{2}\right)}{2}\qedhere
		\end{align*}
	\end{soluzione}
\end{esempio}
\subsection{Valor Medio e Varianza di Variabili Aleatorie Continue} % (fold)
\label{sub:valor_medio_e_varianza_di_variabili_aleatorie_continue}
\begin{definizione}
	Sia $X$ variabile aleatoria continua con densità $f_X$; il suo valor medio è dato da
	\begin{equation*}
		E(X)=\int_{-\infty}^{+\infty}xf_X(x)dx
	\end{equation*}
	se l'integrale esiste finito.
\end{definizione}
\begin{NB}
	Non tutte le variabili aleatorie continue hanno valor medio. Ad esempio, le variabili aleatorie di Cauchy, cioè con densità
	\begin{equation*}
		f_X(x)=\frac{1}{\pi}\frac{1}{x^2+1}
	\end{equation*}
	non hanno valor medio.
\end{NB}
\begin{teorema}
	Sia $X$ una variabile aleatoria continua, sia $g:\mathds{R}\to\mathds{R}$ una funzione sufficientemente regolare. Allora $g(X)$ è ancora una variabile aleatoria continua, ed il suo valor medio è
	\begin{equation*}
		E(g(X))=\int_{-\infty}^{+\infty}g(x)f_X(x)dx
	\end{equation*}
	se l'integrale esiste finito.
\end{teorema}
\begin{nota}
	Chiaramente, potrebbe essere che $X$ abbia valor medio, ma che $g(X)$ non ce l'abbia
\end{nota}
Come applicazione del teorema, possiamo scegliere $g(x)=(x-E(X))^2$ ed ottenere la varianza di $X$ come
\begin{equation*}
	Var(X)=E[(X-E(X))^2]=\int_{-\infty}^{+\infty}(x-E(X))^2f_X(x)dx
\end{equation*}
Come per le variabili aleatorie discrete, vale
\begin{equation*}
	Var(X)=E(X^2)-E(X)^2
\end{equation*}
Chiaramente, anche per calcolare $E(X^2)$ è necessario applicare il teorema.
% subsection valor_medio_e_varianza_di_variabili_aleatorie_continue (end)
\subsection{Variabili Aleatorie Continue Notevoli} % (fold)
\label{sub:variabili_aleatorie_continue_notevoli}
Analogamente alle variabili aleatorie discrete, si possono considerare due variabili equivalenti se hanno la stessa probabilità:
\begin{definizione}
	Siano $X$ e $Y$ due varibili aleatorie continue con stessa funzione densità di probabilità:
	\begin{equation*}
		f_X(x)=f_Y(x)\quad\forall x\in\mathds{R}
	\end{equation*}
	Allora $X$ e $Y$ si dicono probabilisticamente equivalenti e si indica
	\begin{equation*}
		X\sim Y
	\end{equation*}
\end{definizione}
\paragraph{Vaiabili Aleatorie Uniformi} % (fold)
\label{par:vaiabili_aleatorie_uniformi}
Una variabile $X$ si dice uniforme e si indica
\begin{equation*}
	X\sim U(a,b)\quad\text{con }a<b
\end{equation*}
se è caratterizzata da
\begin{align*}
	f_X(x)&=
	\begin{cases}
		\frac{1}{b-a}&\text{se }x\in[a,b]\\
		0&\text{se }x\notin[a,b]
	\end{cases}\\
	F_X(x)&=
	\begin{cases}
		0&\text{se }x<a\\
		\frac{x-a}{b-a}&\text{se }a\leq x\leq b\\
		1&\text{se }x>b
	\end{cases}\\
	E(X)&=\frac{b+a}{2}\\
	Var(X)&=\frac{(b-a)^2}{12}
\end{align*}
Le espressioni di $F_X(x)$, $E(X)$ e $Var(X)$ si ricavano da $f_X(x)$ applicando le definizioni.
% paragraph vaiabili_aleatorie_uniformi (end)
\paragraph{Variabili Aleatorie Esponenziali} % (fold)
\label{par:variabili_aleatorie_esponenziali}
Una variabile $X$ si dice esponenziale e si indica
\begin{equation*}
	X\sim Exp(\lambda)\quad\text{con }\lambda>0
\end{equation*}
se è caratterizzata da
\begin{align*}
	f_X(x)&=
	\begin{cases}
		\lambda e^{-\lambda x}&\text{se }x\geq0\\
		0&\text{se }x<0
	\end{cases}\\
	F_X(x)&=
	\begin{cases}
		0&\text{se }x<0\\
		1-e^{-\lambda x}&\text{se }x\geq0
	\end{cases}\\
	E(X)&=\frac{1}{\lambda}\\
	Var(X)&=\frac{1}{\lambda^2}
\end{align*}
Le espressioni di $F_X(x)$, $E(X)$ e $Var(X)$ si ricavano attraverso le definizioni (per calcolare $E(X)$e $Var(X)$ bisogna integrare per parti).
\subparagraph{Usi delle Variabili Aleatorie Esponenziali} % (fold)
\label{subp:usi_delle_variabili_aleatorie_esponenziali}
Le variabili esponenziali si utilizzano per modellare tempi di primo arrivo o tempi di attesa, e infatti sono fortemente legate alle variabili di Poisson. Supponiamo ad esempio che $N_1$ sia la variabile aleatoria che modella le richieste di servizio di un server per unità di tempo. Tipicamente si assume che $N_1\sim Po(\lambda)$, dove $\lambda$ è il numero medio di richieste al server per unità di tempo. Il numero di richieste in $t$ unità di tempo sarà quindi $N_t\sim Po(\lambda t)$. Definiamo ora $W$ la variabile aleatoria che rappresenta il tempo di attesa fino all'arrivo della prima richiesta; si ha
\begin{equation*}
	P(W>t)=P(N_t=0)=e^{-\lambda t}
\end{equation*}
Segue che
\begin{equation*}
	P(W\leq t)=1-P(W>t)=1-e^{-\lambda t}
\end{equation*}
Se $t$ è un istante infinitesimo di tempo, questa è la funzione di ripartizione di $W$:
\begin{equation*}
	F_X(t)=1-e^{-\lambda t}
\end{equation*}
Quindi $W\sim Exp(\lambda)$.
% subparagraph usi_delle_variabili_aleatorie_esponenziali (end)
\subparagraph{Proprietà di Assenza di Memoria} % (fold)
\label{subp:proprietà_di_assenza_di_memoria}
Se $X\sim Exp(\lambda)$, allora $X$ "non ha memoria":
\begin{equation*}
	P(X\geq T+t|X\geq T)=P(X\geq t)
\end{equation*}
\begin{proof}
	\begin{align*}
		P(X\geq T+t|X\geq T)&=\frac{P(X\geq T+t,X\geq T)}{P(X\geq T)}\\
		&=\frac{P(X\geq T+t)}{P(X\geq T)}\\
		&=\frac{1-P(X\leq T+t)}{1-P(X\leq T)}\\
		&=\frac{1-F_X(T+t)}{1-F_X(T)}\\
		&=\frac{e^{-\lambda (T+t)}}{e^{-\lambda T}}\\
		&=e^{-\lambda t}\\
		&=1-F_X(t)\\
		&=1-P(X\leq t)\\
		&=P(X\geq t)\qedhere
	\end{align*}
\end{proof}
Le variabili esponenziali sono le uniche variabili assolutamente continue ad avere questa proprietà.
% subparagraph proprietà_di_assenza_di_memoria (end)
\begin{esercizio}
	La lunghezza di una telefonata (in minuti) è una variabile aleatoria $X\sim Exp(\frac{1}{10}$. Se qualcuno arriva prima di noi alla cabina telefonica, determinare la probabilità di dover aspettare
	\begin{enumerate}
		\item più di 10 minuti
		\item tra 10 e 20 minuti
	\end{enumerate}
	\begin{soluzione}
		\begin{enumerate}
			\item 
			\begin{align*}
				P(X>10)&=1-P(X\leq 10)\\
				&=1-F_X(10)\\
				&=1-1+e^{-10\cdot\frac{1}{10}}=e^{-1}\approx 0.368
			\end{align*}
			\item 
			\begin{align*}
				P(10< X< 20)&=F_X(20)-F_X(10)\\
				&=1-e^{-20\cdot\frac{1}{10}}-1+e^{-10\cdot\frac{1}{10}}\\
				&=e^{-1}-e^{-2}\approx 0.233\qedhere
			\end{align*}
		\end{enumerate}
	\end{soluzione}
\end{esercizio}
\begin{esercizio}
	Il numero di km che un'automo percorre prima che la batteria ceda è una variabile aleatoria esponenziale di media $10000$. Se una persona desidera fare un viaggio di $5000km$, qual è la probabilità che effettui il viaggio senza cambiare la batteria?
	\begin{soluzione}
		Definiamo $X$ la variabile aleatoria che descrive la durata della batteria misurata in $Mm=10^6m$. Quindi, siccome la media di $X$ è $10$, vale
		\begin{equation*}
			X\sim Exp(\frac{1}{10})
		\end{equation*}
		Sia $T$ il tempo di usura attuale della batteria. Vogliamo calcolare
		\begin{equation*}
			P(X>T+5|X>T)
		\end{equation*}
		Per l'assenza di memoria delle variabili esponenziali:
		\begin{equation*}
			P(X>T+5|X>T)=P(X>5)
		\end{equation*}
		Segue:
		\begin{align*}
			P(X>5)&=1-P(X\leq 5)\\
			&=1-F_X(5)\\
			&=e^{-5\cdot\frac{1}{10}}\\
			&=e^{-\frac{1}{2}}\approx 0.604\qedhere
		\end{align*}
	\end{soluzione}
\end{esercizio}
% paragraph variabili_aleatorie_esponenziali (end)
\paragraph{Variabili Aleatorie Gaussiane o Normali} % (fold)
\label{par:variabili_aleatorie_gaussiane_o_normali}
Una variabile si dice gaussiana o normale e si indica
\begin{equation*}
	X\sim N(\mu, \sigma^2)\quad\text{con }\mu\in\mathds{R},\sigma^2>0
\end{equation*}
se è caratterizzata da
\begin{equation*}
	f_X(x)=\frac{1}{\sqrt{2\pi\sigma^2}}\cdot e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\end{equation*}
\begin{osservazione}
	Per le variabili normali non è possibile dare la funzione di distribuzione perché $e^{-x^2}$ non ammette primitiva in modo analitico.
\end{osservazione}
La funzione densità di $X$ ha un grafico detto "a campana". Il grafico è simmetrico rispetto $\mu$, e la larghezza è data dalla varianza. Calcoliamo $E(X)$:
\begin{align*}
	E(X)&=\int_{-\infty}^{+\infty}x\frac{1}{\sqrt{2\pi\sigma^2}}\cdot e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx\\
	&\text{sommo e sottraggo }\mu\\
	&=\int_{-\infty}^{+\infty}\frac{x-\mu+\mu}{\sqrt{2\pi\sigma^2}}\cdot e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx\\
	&=\int_{-\infty}^{+\infty}\frac{x-\mu}{\sqrt{2\pi\sigma^2}}\cdot e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx+\mu\int_{-\infty}^{+\infty}\frac{1}{\sqrt{2\pi\sigma^2}}\cdot e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx\\
	&\text{il secondo integrale è }1\text{, in quanto la funzione integranda è }f_X(x)\\
	&\text{cambio variabile nel primo integrale: }y=\frac{x-\mu}{\sqrt{2\sigma^2}},\ dy=dx\\
	&=\int_{-\infty}^{+\infty}\frac{y}{\sqrt{\pi}}e^{-y^2}dy+\mu\\
	&\text{la funzine integranda è dispari, e il dominio è simmetrico rispetto }0\\
	&\text{quindi l'integrale è nullo}\\
	&=0+\mu=\mu
\end{align*}
Per calcolare la varianza invece di usare la relazione $Var(X)=E(X^2)-(E(X))^2$ in questo caso è più comodo usare la definizione, perché con lo stesso cambio di variabile di prima e un'integrazione per parti si ricava. Il risultato è $Var(X)=\sigma^2$.
\begin{notazione}
	$\sigma$ si dice deviazione standard.
\end{notazione}
\subparagraph{Trasformazioni Affini di Variabili Normali} % (fold)
\label{subp:trasformazioni_affini_di_variabili_normali}
Sia $X\sim N(\mu,\sigma^2)$, definiamo $Y=aX+b$. Allora
\begin{equation*}
	Y\sim N(a\mu+b,a^2\sigma^2)
\end{equation*}
Quindi non è solo possibile ricavare valor medio e varianza di $Y$ (che sono noti dalle loro proprietà), ma sappiamo anche che $Y$ è ancora normale.
\begin{proof}
	Caratterizziamo i parametri:
	\begin{itemize}
		\item 
		\begin{align*}
			E(Y)&=E(aX+b)\\
			&=aE(X)+b\\
			&=a\mu+b
		\end{align*}
		\item
		\begin{align*}
			Var(Y)&=Var(aX+b)\\
			&=Var(aX)\\
			&=a^2Var(X)\\
			&=a^2\sigma^2
		\end{align*}
	\end{itemize}
	Determiniamo ora la funzione di distribuzione di $Y$: per un generico $y\in\mathds{R}$
	\begin{align*}
		F_Y(y)&=P(Y\leq y)\\
		&=P(aX+b\leq y)\\
		&=P\left(X\leq \frac{y-b}{a}\right)\\
		&=F_X\left(\frac{y-b}{a}\right)
	\end{align*}
	Deriviamo:
	\begin{align*}
		f_Y(y)&=\frac{d}{dy}F_Y(y)\\
		&=\frac{d}{dy}F_X\left(\frac{y-b}{a}\right)\\
		&=F_X'\left(\frac{y-b}{a}\right)\frac{d}{dy}\frac{y-b}{a}\\
		&=f_Y\left(\frac{y-b}{a}\right)\cdot\frac{1}{a}\\
		&=\frac{1}{\sqrt{2\pi\sigma^2}}\cdot e^{-\frac{\left(\frac{y-b}{a}-\mu\right)^2}{2\sigma^2}}\frac{1}{a}\\
		&=\frac{1}{\sqrt{2\pi a^2\sigma^2}}\cdot e^{-\frac{(y-(a\mu+b))^2}{2a^2\sigma^2}}\qedhere
	\end{align*}
\end{proof}
La conseguenza più importante di questa proprietà è che tutte le variabili aleatorie normali si possono ricondurre ad una variabile normale detta centrata standard, che si indica generalmente con $Z$, che ha media $0$ e varianza $1$. Se $X\sim N(\mu,\sigma^2)$, allora la normale centrata standard è data da
\begin{equation*}
	Z=\frac{X-\mu}{\sigma}
\end{equation*}
Questo è molto utile per due motivi:
\begin{enumerate}
	\item Siccome $F_X$ non si può calcolare analiticamente, va stimata con l'analisi numerica; in tabella è fornita la funzione di ripartizione della centrata standard, e tutte le altre vanno ricavate.
	\item Si possono confrontare dati che si distribuiscono con normali molto diverse, riconducendosi alla centrata standard.
\end{enumerate}
\begin{lemma}
	Se $X_1,\dots,X_n$ sono variabili aleatorie normali indipendenti, con
	\begin{equation*}
		X_i\sim N(\mu_i,\sigma_i^2)
	\end{equation*}
	Siano $a_1,\dots,a_n\in\mathds{R}$. Allora
	\begin{equation*}
		\sum_{i=n}^n a_iX_i\sim N(\sum_{i=n}^na_i\mu_i,\sum_{i=n}^na_i^2\sigma_i^2)
	\end{equation*}
\end{lemma}
\begin{notazione}
	La funzione di distribuzione di una variabile normale centrata standard si indica
	\begin{equation*}
		\Phi(z)
	\end{equation*}
\end{notazione}
\begin{esercizio}
	Una macchina confeziona barattoli di caffè del contenuto nominale di $250g$ di caffè. Il peso reale è invece una variabile aleatoria normale di media $250g$.
	\begin{enumerate}
		\item Calcolare la deviazione standard del peso sapendo che il $5\%$ dei barattoli pesa più di $252g$
		\item Calcolare la probabilità che un barattolo pesi meno di $245g$
	\end{enumerate}
	\begin{soluzione}
		\begin{enumerate}
			\item Indichiamo con $X$ il peso dei barattoli, quindi:
			\begin{equation*}
				X\sim N(250, \sigma^2)
			\end{equation*}
			Vogliamo fissare $\sigma$ in modo che
			\begin{equation*}
				P(X>252)=0.05
			\end{equation*}
			Ci riportiamo alla normale centrata standard:
			\begin{align*}
				P\left(\frac{X-250}{\sigma}>\frac{252-250}{\sigma}\right)&=P\left(Z>\frac{2}{\sigma}\right)\\
				&=1-\Phi\left(\frac{2}{\sigma}\right)=0.05\\
			\end{align*}
			Si ha
			\begin{equation*}
				\Phi\left(\frac{2}{\sigma}\right)=0.95
			\end{equation*}
			Da tabella si ricava
			\begin{equation*}
				\frac{2}{\sigma}\approx1.645\Rightarrow \sigma\approx1.22
			\end{equation*}
			\item Normalizziamo e risolviamo:
			\begin{align*}
				P(X<245)&=P\left(\frac{X-250}{1.22}<\frac{245-250}{1.22}\right)\\
				&=P(Z<-4.098)\\
				&=\Phi(-4.098)\\
				&=1-\Phi(4.098)\approx1-1=0\qedhere
			\end{align*}
		\end{enumerate}
	\end{soluzione}
\end{esercizio}
% subparagraph trasformazioni_affini_di_variabili_normali (end)
% paragraph variabili_aleatorie_gaussiane_o_normali (end)
% subsection variabili_aleatorie_continue_notevoli (end)
% section variabili_aleatorie_assolutamente_continue (end)
\section{Teoremi Limite} % (fold)
\label{sec:teoremi_limite}
I teoremi limite sono due teoremi che trattano dei limiti di successioni di variabili aleatorie. Li vediamo nel dettaglio.
\subsection{Legge dei Grandi Numeri} % (fold)
\label{sub:legge_dei_grandi_numeri}
Nell'ambito sperimentale delle scienze, un requisito pressochè fondamentale è che gli esperimenti siano ripetibili, e che abbiano sempre lo stesso risultato. Nella pratica, però, è impossibile ripetere un esperimento in modo esattamente identico, e questo porta ad una certa variabilità nei risultati. D'altro canto, questa variabilità non è completamente caotica, e i risultati sono comunque "piuttosto vicini" al risultato reale. Quest'idea informale si formalizza introducendo il concetto di media empirica: invece di eseguire un dato esperimento una volta sola si esegue più volte e si costruisce la media aritmetica dei valori osservati; questa media, detta empirica, tende ad essere molto più regolare dei singoli risultati, anche al vaglio di ri-esecuzioni dell'esperimento ripetuto. Inoltre, più alto è il numero di ripetizioni, più la media empirica si avvicina al valore reale. Questo risultato sperimentale si formalizza ulteriormente con un risultato molto importante della teoria della probabilità: la legge dei grandi numeri. Consideriamo un dato esperimento ripetuto, e consideriamo $X_i$ la variabile aleatoria associata all'$i$-esima prova. Resta definita quindi una successione $(X_i)_{i\geq1}$ di variabili aleatorie indipendenti (in quanto ogni esecuzione dell'esperimento non influenza le altre) ed identicamente distribuite (perché l'esperimento che viene eseguito è sempre lo stesso) con media finita $\mu$ (hanno tutte la stessa media perché la distribuzione è la stessa). Si può quindi costruire la successione $(\overline{X}_n)_{n\geq1}$ delle medie empiriche come:
\begin{equation*}
	\overline{X}_n=\frac{1}{n}\sum_{i=1}^nX_i
\end{equation*}
Allora si dimostra che vale
\begin{teorema}[Legge dei Grandi Numeri]
	\begin{equation*}
		\lim_{n\to+\infty}P(|\overline{X}_n-\mu|>\varepsilon)=0\quad\forall\varepsilon>0
	\end{equation*}
	equivalentemente:
	\begin{equation*}
		\lim_{n\to+\infty}P(|\overline{X}_n-\mu|\leq\varepsilon)=1\quad\forall\varepsilon>0
	\end{equation*}
\end{teorema}
Essenzialmente, il limite esprime il concetto che abbiamo intuito precedentemente: per un numero $n$ di prove sufficientemente grande la media empirica si avvicina al valor medio (cioè il valore reale), e la distanza fra i due diventa arbitrariamente piccola (infatti, al limite, diventa talmente piccola da essere minore di qualunque $\varepsilon$ positivo piccolo a piacere). Lo stesso risultato si può ottenere per funzioni di variabili aleatorie:
\begin{corollario}
	Sia $(X_i)_{i\geq1}$ una successione di variabili aleatorie come sopra, sia $g:\mathds{R}\to\mathds{R}$ funzione sufficientemente regolare tale che $E(g(X_i))<\infty$ $\forall i$, allora vale
	\begin{equation*}
		\lim_{n\to+\infty}P\left(\left|\frac{1}{n}\sum_{i=1}^ng(X_i)-E(g(X_1))\right|>\varepsilon\right)=0\quad\forall\varepsilon>0
	\end{equation*}
\end{corollario}
\subsubsection{Applicazione: Metodo Montecarlo per il Calcolo di Integrali Definiti} % (fold)
\label{ssub:applicazione_metodo_montecarlo_per_il_calcolo_di_integrali_definiti}
Sappiamo già che alcuni integrali non sono risolvibili analiticamente, perché alcune funzioni non ammettono primitiva. Uno dei metodi più famosi di risoluzione numerica è il metodo Montecarlo, che si basa sull'idea di considerare l'integrale come media di un'opportuna variabile aleatoria ed applicare la legge dei grandi numeri. SUpponiamo di dover calcolare l'integrale
\begin{equation*}
	I=\int_a^bg(x)dx
\end{equation*}
Utilizziamo semplici manipolazioni algebriche per scrivere l'integrale come valore atteso di una variabile aleatoria: cerchiamo di portarlo in una forma simile alla funzione densità di una variabile uniforme.
\begin{equation*}
	I=(b-a)\int_a^b\frac{g(x)}{b-a}dx
\end{equation*}
Se $X\sim U(a,b)$, allora:
\begin{equation*}
	I=(b-a)E(g(X))
\end{equation*}
A questo punto consideriamo $n$ variabili aleatorie $X_1,X_2,\dots,X_n$ indipendenti ed identicamente distribuite, tutte con distribuzione $U(a,b)$, ad esempio generando $n$ copie della stessa variabile aleatoria. Con $n$ sufficientemente grande, per il corollario alla legge dei grandi numeri si può stimare
\begin{equation*}
	\frac{1}{n}\sum_{i=1}^ng(X)\approx E(g(X))=\frac{I}{b-a}
\end{equation*}
Da cui si può ricavare un'approssimazione per $I$.
% subsubsection applicazione_metodo_montecarlo_per_il_calcolo_di_integrali_definiti (end)
% subsection legge_dei_grandi_numeri (end)
\subsection{Teorema del Limite Centrale} % (fold)
\label{sub:teorema_del_limite_centrale}
Nelle applicazioni della Legge dei Grandi Numeri è importante valutare $P(|\overline{X}_n-\mu|>\varepsilon)$ per sapere se $n$ è stato scelto sufficientemente grande affinchè $\overline{X}_n$ sia una buona stima di $\mu$. Questa probabilità generalmente non è facile da valutare, perché $(\overline{X}_n)_{n\geq1}$ non è una successione di variabili indipendenti e identicamente distribuite. Si può calcolare esattamente solo nel caso in cui le variabili $X_i$ siano tutte normali $N(\mu,\sigma^2)$, perché in questo caso $\overline{X}_n$ è ancora una variabile normale (per le proprietà delle trasformazioni affini di variabili normali, essendo una combinazione lineare di variabili normali). In particolare:
\begin{align*}
	\overline{X}_n=\frac{1}{n}\sum_{i=1}^nX_i&\sim N\left(\frac{1}{n}\sum_{i=1}^nE(X_i),\frac{1}{n^2}\sum_{i=1}^nVar(X_i)\right)\\
	&=N\left(\frac{1}{n}\sum_{i=1}^n\mu,\frac{1}{n^2}\sum_{i=1}^n\sigma^2\right)\\
	&=N\left(\frac{1}{n}n\mu,\frac{1}{n^2}n\sigma^2\right)\\
	&=N\left(\mu,\frac{\sigma^2}{n}\right)
\end{align*}
Si ottiene quindi:
\begin{align*}
	P(|\overline{X}_n-\mu|>\varepsilon)&=P\left(\frac{|\overline{X}_n-\mu|}{\frac{\sigma}{\sqrt{n}}}>\frac{\varepsilon}{\frac{\sigma}{\sqrt{n}}}\right)\\
	&=2\Phi\left(\frac{\varepsilon}{\frac{\sigma}{\sqrt{n}}}\right)-1
\end{align*}
Quindi, in questo caso è sempre possibile fissare una tolleranza $\varepsilon$ e una confidenza (cioè una probabilità) $p$, e ricavare il numero $n$ di prove necessarie a stimare $\mu$ con $\overline{X}_n$ con confidenza $p$ e commettendo un errore di alpiù $\varepsilon$. Se le variabili $X_i$ non sono normali, ci possiamo ricondurre a questo caso particolare attraverso il teorema del limite centrale. Consideriamo $(X_i)_{i\geq1}$ una successione di variabili aleatorie indipendenti e identicamente distribuite, con valore atteso $E(X_i)=\mu<\infty$ e varianza $Var(X_i)=\sigma^2<+\infty$; costruiamo la successione $(Z_n)_{n\geq1}$ data da
\begin{equation*}
	Z_n=\frac{\overline{X}_n-\mu}{\frac{\sigma}{\sqrt{n}}}
\end{equation*}
$Z_n$ si dice standardizzazione della variabile $X_n$. Resta definita la successione $(F_{Z_n})_{n\geq1}$ delle funzioni di ripartizione di queste variabili.
\begin{teorema}[del Limite Centrale]
	\begin{equation*}
		\lim_{n\to+\infty}F_{Z_n}(z)=\Phi(z)\quad\forall z\in\mathds{R}
	\end{equation*}
	con $\Phi(z)$ funzione di ripartizione di $Z\sim N(0,1)$.
\end{teorema}
L'idea è che, per $n$ grandi, si può sempre approssimare la probabilità di eventi relativi alla media empirica standardizzata calcolando la probabilità dei rispettivi eventi equivalenti per una variabile aleatoria normale centrata standard. Quest'approssimazione è detta \textit{approssimazione normale}.
\begin{osservazione}
	Va notato che non c'è nessuna ipotesi sulle variabili $X_i$ (oltre alla loro indipendenza ed identica distribuzione); il teorema del Limite Centrale si può applicare a variabili aleatorie qualunque.
\end{osservazione}
% subsection teorema_del_limite_centrale (end)
% section teoremi_limite (end)
\section{Cenni di Statistica} % (fold)
\label{sec:cenni_di_statistica}
La statistica non è una scienza esatta, perché raccoglie dati, li analizza, li interpreta, e cerca di ricavare informazioni generali su una popolazione  partire da una sua porzione ristretta. A tutti questi livelli, in particolare per quanto riguarda l'interpretazione ma non solo, è presente un livello piuttosto alto di empirismo, che si traduce in un'influenza soggettiva sul risultato. La statistica ha due aspetti:
\begin{itemize}
	\item La statistica descrittiva cerca di estrapolare informazioni quantitative da un insieme di dati per descriverlo, attraverso tabelle di frequenza, indici, e altre quantità informative
	\item La statistica inferenziale cerca di prevedere, con livelli diversi di affidabilità, eventi futuri sulla base di osservazioni presenti o passate; la statistica inferenziale è più vicina alla probabilità che abbiamo visto, perché cerca di inquadrare i dati in un modello probabilistico, e usa questo modello per calcolare con quale probabilità si verificheranno specifici eventi futuri
\end{itemize}
\subsection{Statistica Descrittiva} % (fold)
\label{sub:statistica_descrittiva}
I mezzi utilizzati dalla statistica descrittiva sono:
\begin{itemize}
	\item Tabelle e grafici, per una rappresentazione sintetica dei dati
	\item Strumenti matematici (come media, mediana, e altri indici), per dare informazioni quantitative sui dati
\end{itemize}
I dati analizzati possono essere:
\begin{itemize}
	\item Numerici, se sono numeri. Possono essere
	\begin{itemize}
		\item Variabili discrete (ad esempio età, o numero di scarpe)
		\item Variabili continue (come misure di lunghezze, o tempi di vita)
	\end{itemize}
	\item Categorici, se non sono numerici
\end{itemize}
I dati presentati in una tabella così come sono stati raccolti si dicono \textit{dati grezzi} e sono piuttosto difficili da analizzare, quindi vanno "sgrezzati". Un modo di pulire i dati si ha dividendoli in classi ed analizzando le frequenze per ciascuna classe. C'è una forte arbitrarietà sull'ampiezza delle classi: non si è ancora definito un metodo rigoroso per decidere l'ampiezza ottimale. La frequenza di una classe può essere di tre tipi:
\begin{itemize}
	\item Assoluta: rappresenta il numero di volte in cui un dato ha assunto un valore interno alla classe nel campione analizzato
	\item Relativa: rappresenta il rapporto fra la frequenza assoluta e la numerosità del campione; è fortemente analoga al concetto di probabilità
	\item Relativa Cumulativa: rappresenta la somma delle frequenze relative di tutte le classi precedenti, fino alla classe in esame (compresa); è analoga al concetto di funzione di ripartizione
\end{itemize}
Una proprietà delle frequenze è che la somma delle frequenze assolute deve essere uguale alla numerosità del campione, la somma delle frequenze relative deve essere $1$, e la frequenza cumulativa dell'ultima classe deve essere $1$. Mentre per dati discreti la divisione in classi è opzionale, ma spesso molto utile, per i dati continui è necessaria. Per i dati categorici non ha senso parlare di frequenze cumulative, perché spesso non è presente un ordinamento.
\paragraph{Metodi Grafici} % (fold)
\label{par:metodi_grafici}
Servono per rappresentare i dati in modo più immediatamente riconoscibile.
\subparagraph{Istogramma} % (fold)
\label{subp:istogramma}
Utilizzabile per dati numerici; formato da rettangoli con le basi adiacenti che rappresentano le frequenze delle varie classi. Se le classi sono date da degli intervalli $(a_j,b_j)$, il $j$-esimo rettangolo avrà per base il segmento delimitato da $a_j$ e $b_j$ sull'asse $x$. L'altezza si può scegliere pari alla frequenza (relativa o assoluta), oppure pari alla frequenza divisa per l'ampiezza della classe. Nel secondo caso, la frequenza sarà data dall'area del rettangolo.
% subparagraph istogramma (end)
\subparagraph{Diagramma a Barre} % (fold)
\label{subp:diagramma_a_barre}
Equivalente all'istogramma, ma per dati categorici; la differenza fondamentale è che le basi dei rettangoli non hanno nessun significato, e devono essere non adiacenti (separate da dello spazio) perché sia immediatamente evidente che i dati non sono numerici.
% subparagraph diagramma_a_barre (end)
% paragraph metodi_grafici (end)
\paragraph{Indici Numerici} % (fold)
\label{par:indici_numerici}
Sono degli indici che danno alcune idee sulla forma dei dati e sul modo in cui si distribuiscono. Consideriamo una sequenza $(x_i)_{1\leq i\leq n}$ di $n$ valori.
\begin{NB}
	Generalmente i dati in un campione hanno un'unità di misura, quinid gli indice devono avere unità di misura consistenti.
\end{NB}
\subparagraph{Media Campionaria} % (fold)
\label{subp:media_campionaria}
È un indice di centralità, dà una stima della posizione del centro dei dati, cioè un numero vicino al quale si posizionano i dati; corrisponde alla media aritmetica dei dati:
\begin{equation*}
	\overline{x}=\frac{1}{n}\sum_{i=1}^nx_i
\end{equation*}
Risente fortemente di dati estremi, o estremamente distanti dagli altri.
% subparagraph media_campionaria (end)
\subparagraph{Mediana} % (fold)
\label{subp:mediana}
Ancora un indice di centralità; se i dati vengono disposti in ordine non decrescente, la mediana è il numero centrale nella sequenza, cioè quello che divide il campione in due parti di egual numerosità, e quindi non risente dei dati estremi:
\begin{equation*}
	M=
	\begin{cases}
		x_{\frac{n+1}{2}}&\text{se }n\text{ è dispari}\\
		\frac{1}{2}(x_{\frac{n}{2}}+x_{\frac{n}{2}+1})&\text{se }n\text{ è pari}
	\end{cases}
\end{equation*}
% subparagraph mediana (end)
\subparagraph{Moda} % (fold)
\label{subp:moda}
Un ulteriore indice di centralità; rappresenta il dato (o la classe) con frequenza assoluta più alta. Per un dato campione ci possono essere più mode, cioè più dati che hanno tutti la stessa frequenza, più alta degli altri; un campione di questo tipo si dice plurimodale.
% subparagraph moda (end)
\subparagraph{Varianza Campionaria} % (fold)
\label{subp:varianza_campionaria}
Stima la dispersione dei dati: più è piccola, più i dati sono concentrati attorno alla media campionaria
\begin{equation*}
	s^2=\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})^2
\end{equation*}
Si divide per $n-1$ e non per $n$ per un motivo teorico che vedremo più avanti.
% subparagraph varianza_campionaria (end)
\subparagraph{Deviazione Standard Campionaria} % (fold)
\label{subp:deviazione_standard_campionaria}
Corisponde alla radice quadrata (positiva) della varianza campionaria
\begin{equation*}
	s=+\sqrt{s^2}
\end{equation*}
% subparagraph deviazione_standard_campionaria (end)
\subparagraph{$p$-esimo Quantile} % (fold)
\label{subp:p_esimo_quantile}
Generalizzazione del concetto di mediana: se il campione è ordinato in modo non decrescente, si può cercare quale dato divide il campione in una porzione contenente una certa frazione $p$ ($0<p<1$) dei dati, e una porzione contenente il resto.
\begin{equation*}
	q_p=
	\begin{cases}
		x_{\lfloor{np}\rfloor+1}&\text{se }np\text{ non è intero}\\
		\frac{1}{2}(x_{np}+x_{np+1})&\text{se }np\text{ è intero}
	\end{cases}
\end{equation*}
Il $p$-esimo quantile si dice anche $(100p)$-esimo percentile. Il $25°$, $50°$ e $75°$ percentile si chiamano primo, secondo e terzo quartile, si indicano $Q_1$, $Q_2$ e $Q_3$, e dividono il campione in quattro parti uguali. Il secondo quartile è la mediana. I quantili sono indici di posizione, ma possono definire un indice di dispersione: la differenza interquartile, pari alla differenza fra il terzo e il primo quartile
\begin{equation*}
	IQR=|Q_3-Q_1|
\end{equation*}
Generalmente si considerano validi solo i dati compresi fra un limite inferiore $L=Q_1-k_1IQR$ e un limite superiore $U=Q_3+k_2IQR$, mentre gli altri si considerano outliers, cioè dati estremi che devono essere riconsiderati perché molto distanti dal trend generale. Le costanti $k_1$ e $k_2$ si possono scegliere in modi diversi; molti programmi usano $k_1=k_2=1.5$. Per rappresentare questa situazione si usa un grafico boxplot, o box and whisker plot: si rappresenta sull'asse delle ascisse il range di appartenenza dei dati, si fissano i tre quartili, e si rappresenta con un quadrato (la scatola) l'insieme dei dati compresi fra $Q_1$ e $Q_3$ (che avrà numerosità $IQR$). Sotto e sopra il quadrato si posizionano due segmenti verticali (i baffi) che si allungano fino rispettivamente $L$ e $U$, ad indicare il range dei dati considerati validi. I dati outlier si indicano con dei circoletti. Plottando più boxplot nello stesso grafico si possono confrontare misure analoghe su campioni diversi.
% subparagraph p_esimo_quantile (end)
% paragraph indici_numerici (end)
% subsection statistica_descrittiva (end)
\subsection{Statistica Inferenziale} % (fold)
\label{sub:statistica_inferenziale}
Si occupa di descrivere dati attraverso modelli probabilistici, al fine di ricercare proprietà generali di una popolazione a partire da osservazioni relative a un campione ristretto. Supponiamo che i dati siano realizzazioni di una variabile aleatoria $X$, la cui caratterizzazione è però ignota. Grazie alla statistica descrittiva è possibile intuire (approssimativamente) la forma della funzione $f_\theta(x)$ con cui si distribuisce $X$, ma rimane ignoto il parametro $\theta$; questo parametro dovrà essere stimato, per poi causare un'eventuale modifica della forma di $f_\theta(x)$ per cercare una stima migliore. Diamo alcune definizioni:
\begin{definizione}
	Un modello statistico è una famiglia di densità dipendenti da un parametro $\theta$, eventualmente vettoriale:
	\begin{equation*}
		\{f_\theta(x)|\theta\in\Theta\}
	\end{equation*}
\end{definizione}
\begin{definizione}
	Si dice campione casuale una $n$-upla di variabili aleatorie aventi tutte la stessa distribuzione.
\end{definizione}
\begin{definizione}
	Si dice campione una realizzazione di un campione casuale.
\end{definizione}
\begin{definizione}
	Sia $(X_1,\dots,X_n)$ un campione casuale e sia $g:\mathds{R}^n\to\mathds{R}$ una funzione sufficientemente regolare. Si dice statistica una variabile aleatoria
	\begin{equation*}
		T=g(X_1,\dots,X_n)
	\end{equation*}
	che sia funzione solo del campione (e non del parametro $\theta$).
\end{definizione}
\begin{definizione}
	Dato un modello statistico $\{f_\theta(x)|\theta\in\Theta\}$ e una funzione $\tau:\Theta\to\mathds{R}$, una statistica $T$ si dice stimatore di $\tau$ se è usata per stimare il suo valore.
\end{definizione}
\begin{definizione}
	Si dice stima il valore assunto da uno stimatore quando il campione casuale viene sostituito con il campione (cioè con i dati).
\end{definizione}
Segue dalla definizione che da campioni diversi si calcolano stime diverse, ma ci sono alcuni criteri per assicurare che al crescere del campione diminuisca l'errore commesso considerando la stima invece del valore reale.
\begin{definizione}
	Uno stimatore $T$ si dice corretto o non distorto se $E_{\theta}=\tau(\theta)$.
\end{definizione}
\begin{definizione}
	Uno stimatore $T$ si dice consistente se
	\begin{equation*}
		Var_\theta(T)\xrightarrow{n\to+\infty}0
	\end{equation*}
\end{definizione}
L'utilizzo di statistiche per ricavare una stima del valore vero è detta stima puntuale; è una metodologia molto ottimistica, perché al variare del campione può cambiare pesantemente. Per considerare questa variabilità si può usare la stima per intervalli, cioè ricavare degli intervalli entro i quali è più probabile trovare il valor vero, ma noi non la facciamo. In generale, uno stimatore molto buono del valor medio è la media campionaria, perché è corretto e consistente. Per stimare la varianza $\sigma^2$ non si può usare lo stimatore
\begin{equation*}
	T=\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X})^2
\end{equation*}
perché è leggermente distorto: risulta
\begin{equation*}
	E(T)=\frac{n-1}{n}\sigma^2
\end{equation*}
segue che uno stimatore corretto e consistente è
\begin{equation*}
	\frac{n}{n-1}T=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X})^2
\end{equation*}
% subsection statistica_inferenziale (end)
% section cenni_di_statistica (end)
\end{document}